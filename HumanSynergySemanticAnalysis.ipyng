# ======================================================================
#
#  äººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ  V2 - ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æç‰ˆ
#
#  V1ã‹ã‚‰ã®æ”¹å–„ç‚¹:
#  - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®åˆ†æã‚’å»ƒæ­¢
#  - sentence-transformers ã‚’ç”¨ã„ãŸæ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆEmbeddingï¼‰ã«ã‚ˆã‚‹åˆ†æã‚’å°å…¥
#  - ã‚ˆã‚Šç²¾ç·»ã§ä¿¡é ¼æ€§ã®é«˜ã„ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—ã¨ä¾¡å€¤è²¢çŒ®åº¦åˆ†æã‚’å®Ÿç¾
#
# ======================================================================


# ===============================================================
# STEP 1: å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š
# ===============================================================

# V2ã§æ–°ãŸã«è¿½åŠ ï¼šæ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
!pip install sentence-transformers --quiet

# V1ã‹ã‚‰ç¶™ç¶šã—ã¦ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
!pip install networkx matplotlib seaborn plotly kaleido --quiet
!pip install scikit-learn pandas numpy scipy --quiet

# Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆ
from google.colab import drive
drive.mount('/content/drive')

# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# æ•°å­¦ãƒ»çµ±è¨ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from scipy.integrate import odeint
from sklearn.metrics.pairwise import cosine_similarity

# NLPï¼ˆè‡ªç„¶è¨€èªå‡¦ç†ï¼‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sentence_transformers import SentenceTransformer

# ãã®ä»–
import re
from datetime import datetime

print("âœ… V2: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸ")


# ===============================================================
# STEP 2: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ï¼ˆV1ã‹ã‚‰å¤‰æ›´ãªã—ï¼‰
# ===============================================================

def load_profile_data():
    """Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    base_path = "/content/drive/MyDrive/"
    profiles = {}
    names = ["arale_cohen", "yanay_geva", "yasuyuki_sakane"]
    display_names = ["Arale Cohen", "Yanay Geva", "Yasuyuki Sakane"]

    for name, display_name in zip(names, display_names):
        try:
            with open(f"{base_path}{name}_profile.txt", 'r', encoding='utf-8') as f:
                content = f.read()
            profiles[display_name] = content
            print(f"âœ… {display_name}ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except FileNotFoundError:
            print(f"âš ï¸ {name}_profile.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            profiles[display_name] = "Profile data not available."
    return profiles

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Ÿè¡Œ
profiles = load_profile_data()


# ===============================================================
# STEP 3: ã€V2ã®æ ¸å¿ƒã€‘ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æ
# ===============================================================

class SemanticProfileAnalyzer:
    def __init__(self):
        # äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        # 'all-MiniLM-L6-v2' ã¯é«˜é€Ÿã‹ã¤é«˜å“è³ªãªè‹±èªãƒ¢ãƒ‡ãƒ«
        print("ğŸ¤– è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… è¨€èªãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")

    def analyze_all_profiles(self, profiles_dict):
        """ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã€ä»–ã®ç‰¹å¾´ã‚‚æŠ½å‡ºã™ã‚‹"""
        analysis_results = {}
        profile_names = list(profiles_dict.keys())
        profile_texts = list(profiles_dict.values())

        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å…¨ä½“ã‚’æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã«ä¸€æ‹¬å¤‰æ›
        print("ğŸ§  å…¨å“¡ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ä¸­...")
        embeddings = self.model.encode(profile_texts, show_progress_bar=True)
        print("âœ… ãƒ™ã‚¯ãƒˆãƒ«å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸ")

        for i, name in enumerate(profile_names):
            # çµŒé¨“å¹´æ•°ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦ã¯V1ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ‰‹æ³•ã‚’æµç”¨
            # NOTE: ã“ã‚Œã‚‰ã®æŠ½å‡ºæ–¹æ³•ã‚‚ã€å°†æ¥çš„ã«ã¯ã‚ˆã‚Šé«˜åº¦åŒ–ã§ãã‚‹
            experience = self._extract_experience_years(profile_texts[i])
            network = self._extract_network_strength(profile_texts[i])

            analysis_results[name] = {
                'embedding': embeddings[i], # æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«
                'experience_years': experience,
                'network_strength': network,
                'raw_profile': profile_texts[i]
            }
        return analysis_results

    def _extract_experience_years(self, text):
        """çµŒé¨“å¹´æ•°ã‚’æŠ½å‡º"""
        matches = re.findall(r'(\d+)\+?\s*years?', text.lower())
        return max([int(match) for match in matches]) if matches else 10

    def _extract_network_strength(self, text):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦ã‚’æ¨å®š"""
        indicators = ['network', 'ecosystem', 'connections', 'board member', 'partner']
        score = sum(text.lower().count(indicator) for indicator in indicators)
        return min(score * 20, 100)

# ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æå®Ÿè¡Œ
analyzer = SemanticProfileAnalyzer()
analysis_data = analyzer.analyze_all_profiles(profiles)

print("âœ… V2: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")


# ===============================================================
# STEP 4: ã€V2ã®æ ¸å¿ƒã€‘ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—
# ===============================================================

class SemanticSynergyCalculator:
    def __init__(self, analysis_data):
        self.data = analysis_data
        self.names = list(analysis_data.keys())

    def calculate_skill_complementarity(self):
        """æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ç”¨ã„ã¦ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã‚’è¨ˆç®—"""
        # å…¨å“¡ã®æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚¹ã‚¿ãƒƒã‚¯
        embeddings = np.array([self.data[name]['embedding'] for name in self.names])

        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®— (å€¤ãŒé«˜ã„ã»ã©ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆãŒè¿‘ã„)
        similarity_matrix = cosine_similarity(embeddings)

        # è£œå®Œæ€§ã¯ (1 - é¡ä¼¼åº¦) ã§å®šç¾©
        complementarity_matrix = 1 - similarity_matrix
        return complementarity_matrix

    def calculate_total_synergy_matrix(self):
        """ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—"""
        # V2: ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã®è¨ˆç®—æ–¹æ³•ãŒæ–°ã—ããªã£ãŸ
        comp_matrix = self.calculate_skill_complementarity()

        # V1ã‹ã‚‰æµç”¨ã™ã‚‹è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
        experiences = [self.data[name]['experience_years'] for name in self.names]
        networks = [self.data[name]['network_strength'] for name in self.names]
        exp_matrix = self._calculate_experience_synergy(experiences)
        net_matrix = self._calculate_network_effects(networks)
        div_matrix = self._calculate_cultural_diversity_bonus()

        # é‡ã¿ä»˜ãçµ±åˆï¼ˆèª¿æ•´å¯èƒ½ï¼‰
        weights = {
            'complementarity': 0.4, # ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã®é‡è¦åº¦ã‚’ä¸Šã’ã‚‹
            'experience': 0.2,
            'network': 0.2,
            'diversity': 0.2
        }

        total_synergy = (
            weights['complementarity'] * comp_matrix +
            weights['experience'] * exp_matrix +
            weights['network'] * net_matrix
        ) * div_matrix # å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹ã¯ä¹—ç®—ã§é©ç”¨

        # è‡ªåˆ†è‡ªèº«ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã¯0ã«ã™ã‚‹
        np.fill_diagonal(total_synergy, 0)

        return {
            'total_synergy': total_synergy,
            'skill_complementarity': comp_matrix
        }

    # ä»¥ä¸‹ã¯V1ã‹ã‚‰æµç”¨ã™ã‚‹ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰
    def _calculate_experience_synergy(self, experiences):
        synergy_matrix = np.zeros((3, 3))
        for i, j in np.ndindex(synergy_matrix.shape):
            if i != j:
                exp_diff = abs(experiences[i] - experiences[j])
                synergy_matrix[i, j] = np.exp(-0.1 * exp_diff) # å·®ãŒå°ã•ã„ã»ã©é«˜ã„
        return synergy_matrix

    def _calculate_network_effects(self, networks):
        network_matrix = np.zeros((3, 3))
        for i, j in np.ndindex(network_matrix.shape):
            if i != j:
                network_matrix[i, j] = (networks[i] * networks[j]) / 10000.0
        return network_matrix

    def _calculate_cultural_diversity_bonus(self):
        backgrounds = {'Arale Cohen': 'Western', 'Yanay Geva': 'Western', 'Yasuyuki Sakane': 'Eastern'}
        diversity_matrix = np.ones((3, 3))
        for i, name1 in enumerate(self.names):
            for j, name2 in enumerate(self.names):
                if backgrounds[name1] != backgrounds[name2]:
                    diversity_matrix[i, j] = 1.2 # ç•°ãªã‚‹æ–‡åŒ–èƒŒæ™¯ã«20%ã®ãƒœãƒ¼ãƒŠã‚¹
        return diversity_matrix

# ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—å®Ÿè¡Œ
synergy_calc = SemanticSynergyCalculator(analysis_data)
synergy_results = synergy_calc.calculate_total_synergy_matrix()

print("âœ… V2: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ")


# ===============================================================
# STEP 5: å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆå®‰å®šç‰ˆã‚’æ¨™æº–æ­è¼‰ï¼‰
# ===============================================================

# ä»¥å‰ã®å¯¾è©±ã§å®‰å®šåŒ–ã—ãŸæœ€çµ‚ç‰ˆã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ä½¿ç”¨
class DynamicSystemModel:
    def __init__(self, synergy_results, analysis_data):
        self.synergy_matrix = synergy_results['total_synergy']
        self.data = analysis_data
        self.names = list(analysis_data.keys())

    def define_system_parameters(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ï¼ˆå®‰å®šæ€§ã‚’æœ€å„ªå…ˆã—ãŸãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯æˆé•·ãƒ¢ãƒ‡ãƒ«ï¼‰"""
        alpha = np.array([0.4, 0.35, 0.45]) # å€‹äººã®åŸºç¤æˆé•·ç‡
        beta = self.synergy_matrix * 0.1 # ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ
        K = np.array([12.0, 12.0, 12.0]) # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šé™
        return alpha, beta, K

    def system_dynamics(self, state, t, alpha, beta, K):
        """å‹•çš„ã‚·ã‚¹ãƒ†ãƒ æ–¹ç¨‹å¼ï¼ˆçµåˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯æˆé•·ãƒ¢ãƒ‡ãƒ«ï¼‰"""
        x1, x2, x3 = state
        dx1dt = (alpha[0] * x1 + beta[0,1] * x2 + beta[0,2] * x3) * (1 - x1 / K[0])
        dx2dt = (alpha[1] * x2 + beta[1,0] * x1 + beta[1,2] * x3) * (1 - x2 / K[1])
        dx3dt = (alpha[2] * x3 + beta[2,0] * x1 + beta[2,1] * x2) * (1 - x3 / K[2])
        return [dx1dt, dx2dt, dx3dt]

    def simulate_growth(self, initial_state=None, time_horizon=24):
        """æˆé•·ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        if initial_state is None:
            initial_state = [1.0, 1.0, 1.0] # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’1.0ã«è¨­å®š
        alpha, beta, K = self.define_system_parameters()
        t = np.linspace(0, time_horizon, time_horizon * 4)
        solution = odeint(self.system_dynamics, initial_state, t, args=(alpha, beta, K))
        return t, solution, (alpha, beta, K)

# å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
dynamic_model = DynamicSystemModel(synergy_results, analysis_data)
time_axis, growth_solution, _ = dynamic_model.simulate_growth()

print("âœ… V2: å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ")


# ===============================================================
# STEP 6: ã‚²ãƒ¼ãƒ ç†è«–åˆ†æï¼ˆã‚ˆã‚Šæ„å‘³ã®ã‚ã‚‹å…¥åŠ›ã§å®Ÿè¡Œï¼‰
# ===============================================================
# V2ã®ç²¾ç·»åŒ–ã•ã‚ŒãŸã‚·ãƒŠã‚¸ãƒ¼å€¤ã‚’å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã€
# ã‚²ãƒ¼ãƒ ç†è«–åˆ†æã®çµæœã‚‚ã€ã‚ˆã‚Šç¾å®Ÿçš„ãªã‚‚ã®ã«ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹

class GameTheoryAnalysis:
    def __init__(self, synergy_results, analysis_data):
        self.synergy_matrix = synergy_results['total_synergy']
        self.data = analysis_data
        self.names = list(analysis_data.keys())
        self.n_players = len(self.names)

    def _get_coalition_value(self, coalition_indices):
        """é€£åˆã®ä¾¡å€¤ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°"""
        if not coalition_indices:
            return 0

        # é€£åˆå†…ã®å€‹äººã®åŸºç¤ä¾¡å€¤ã®åˆè¨ˆ
        base_value = sum((self.data[self.names[i]]['experience_years'] +
                          self.data[self.names[i]]['network_strength'] / 10.0)
                         for i in coalition_indices)

        # é€£åˆå†…ã®ã‚·ãƒŠã‚¸ãƒ¼ã®åˆè¨ˆ
        synergy_value = 0
        if len(coalition_indices) > 1:
            for i in coalition_indices:
                for j in coalition_indices:
                    synergy_value += self.synergy_matrix[i, j]

        # åŸºç¤ä¾¡å€¤ã¨ã‚·ãƒŠã‚¸ãƒ¼ä¾¡å€¤ã‚’çµ±åˆ
        return base_value + synergy_value * 5 # ã‚·ãƒŠã‚¸ãƒ¼ã®ä¾¡å€¤ã‚’å¼·èª¿

    def calculate_shapley_values(self):
        """ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã‚’è¨ˆç®—"""
        from math import factorial
        from itertools import combinations

        shapley_values = np.zeros(self.n_players)
        all_players_set = set(range(self.n_players))

        for i in range(self.n_players):
            for coalition_size in range(self.n_players):
                num_combinations = 0
                total_marginal_contribution = 0

                other_players = list(all_players_set - {i})
                for coalition in combinations(other_players, coalition_size):
                    coalition_with_i = list(coalition) + [i]
                    coalition_without_i = list(coalition)

                    marginal_contribution = self._get_coalition_value(coalition_with_i) - self._get_coalition_value(coalition_without_i)
                    shapley_values[i] += marginal_contribution

        # æ­£è¦åŒ–
        total_value_all_players = self._get_coalition_value(list(all_players_set))
        current_total_shapley = np.sum(shapley_values)
        if current_total_shapley > 0:
            shapley_values = (shapley_values / current_total_shapley) * total_value_all_players

        return shapley_values

# ã‚²ãƒ¼ãƒ ç†è«–åˆ†æå®Ÿè¡Œ
game_analysis = GameTheoryAnalysis(synergy_results, analysis_data)
shapley_values = game_analysis.calculate_shapley_values()

print("âœ… V2: ã‚²ãƒ¼ãƒ ç†è«–åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")


# ===============================================================
# STEP 7: äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆå®‰å®šã—ãŸå…¥åŠ›ã§å®Ÿè¡Œï¼‰
# ===============================================================

class PredictionModel:
    def __init__(self, growth_solution, time_axis, synergy_results):
        self.growth_data = growth_solution
        self.time_axis = time_axis
        self.synergy_matrix = synergy_results['total_synergy']

    def forecast_business_metrics(self):
        """ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™äºˆæ¸¬"""
        performance_data = []
        for t in range(len(self.time_axis)):
            individual_performance = self.growth_data[t]
            # team_synergy ã®è¨ˆç®—å¼ã‚’ã‚ˆã‚Šå®‰å®šãªã‚‚ã®ã«
            team_synergy = np.sum(self.synergy_matrix * np.outer(individual_performance, individual_performance)) / 2

            # å„æŒ‡æ¨™ã®è¨ˆç®—
            revenue_growth = np.sum(individual_performance) * 10 + team_synergy * 5
            innovation_index = team_synergy * 10
            market_share = min(np.sum(individual_performance) + team_synergy, 40)
            customer_satisfaction = min(75 + team_synergy, 98)

            performance_data.append({
                'time_months': self.time_axis[t],
                'revenue_growth_rate': revenue_growth,
                'innovation_index': innovation_index,
                'market_share_percent': market_share,
                'customer_satisfaction': customer_satisfaction
            })
        return pd.DataFrame(performance_data)

# äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å®Ÿè¡Œ
prediction_model = PredictionModel(growth_solution, time_axis, synergy_results)
business_forecast = prediction_model.forecast_business_metrics()

print("âœ… V2: äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ")


# ===============================================================
# STEP 8: å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆV1ã‹ã‚‰ã‚³ãƒ¼ãƒ‰æµç”¨ã€æç”»å†…å®¹ãŒå¤‰åŒ–ï¼‰
# ===============================================================

# V1ã®VisualizationEngineã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒå¤‰ã‚ã‚‹ã“ã¨ã§
# V2ã®åˆ†æçµæœã‚’å¯è¦–åŒ–ã™ã‚‹å½¹å‰²ã‚’æ‹…ã†
class VisualizationEngine:
    def __init__(self, analysis_data, synergy_results, growth_solution,
                 time_axis, business_forecast, shapley_values):
        self.analysis_data = analysis_data
        self.synergy_results = synergy_results
        self.growth_solution = growth_solution
        self.time_axis = time_axis
        self.business_forecast = business_forecast
        self.shapley_values = shapley_values
        self.names = list(analysis_data.keys())

    def create_synergy_heatmap(self):
        """ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"""
        synergy_matrix = self.synergy_results['total_synergy']
        fig = px.imshow(synergy_matrix,
                        labels=dict(x="ãƒ¡ãƒ³ãƒãƒ¼", y="ãƒ¡ãƒ³ãƒãƒ¼", color="ã‚·ãƒŠã‚¸ãƒ¼å¼·åº¦"),
                        x=self.names, y=self.names,
                        text_auto='.3f',
                        color_continuous_scale='Blues')
        fig.update_layout(title_text='V2: ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ç‰ˆï¼‰')
        return fig

    def create_growth_trajectory(self):
        """å‹•çš„æˆé•·è»Œé“"""
        df = pd.DataFrame(self.growth_solution, columns=self.names)
        df['Time'] = self.time_axis
        fig = px.line(df, x='Time', y=self.names,
                      labels={'value': 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ•°', 'Time': 'æ™‚é–“ï¼ˆæœˆï¼‰'},
                      title='V2: å‹•çš„æˆé•·è»Œé“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®‰å®šç‰ˆï¼‰')
        return fig

    def create_business_metrics_dashboard(self):
        """ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
        df = self.business_forecast
        fig = make_subplots(rows=2, cols=2, subplot_titles=('å£²ä¸Šæˆé•·ç‡', 'ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°', 'ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢', 'é¡§å®¢æº€è¶³åº¦'))
        fig.add_trace(go.Scatter(x=df['time_months'], y=df['revenue_growth_rate'], name='å£²ä¸Šæˆé•·ç‡'), row=1, col=1)
        fig.add_trace(go.Scatter(x=df['time_months'], y=df['innovation_index'], name='ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°'), row=1, col=2)
        fig.add_trace(go.Scatter(x=df['time_months'], y=df['market_share_percent'], name='ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢'), row=2, col=1)
        fig.add_trace(go.Scatter(x=df['time_months'], y=df['customer_satisfaction'], name='é¡§å®¢æº€è¶³åº¦'), row=2, col=2)
        fig.update_layout(title_text='V2: ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰', showlegend=False)
        return fig

    def create_shapley_value_chart(self):
        """ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã«ã‚ˆã‚‹ä¾¡å€¤è²¢çŒ®åº¦"""
        fig = px.bar(x=self.names, y=self.shapley_values,
                     labels={'x': 'ãƒ¡ãƒ³ãƒãƒ¼', 'y': 'ä¾¡å€¤è²¢çŒ®åº¦ï¼ˆã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ï¼‰'},
                     text=np.round(self.shapley_values, 2),
                     title='V2: ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã«ã‚ˆã‚‹ä¾¡å€¤è²¢çŒ®åº¦åˆ†æ')
        return fig

    def create_network_graph(self):
        """V1ã®ãƒã‚°ã‚’ä¿®æ­£ã—ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•"""
        G = nx.Graph()
        for i, name in enumerate(self.names):
            G.add_node(name, size=self.analysis_data[name]['network_strength'])

        synergy_matrix = self.synergy_results['total_synergy']
        for i, j in np.ndindex(synergy_matrix.shape):
            if i < j:
                G.add_edge(self.names[i], self.names[j], weight=synergy_matrix[i, j])

        pos = nx.spring_layout(G, k=1.5, iterations=50)

        edge_traces = []
        for edge in G.edges(data=True):
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            w = edge[2]['weight'] * 15
            edge_traces.append(go.Scatter(x=[x0, x1, None], y=[y0, y1, None], mode='lines',
                                        line=dict(width=w, color='rgba(150,150,150,0.5)'),
                                        hoverinfo='text', text=f"Synergy: {w/15:.3f}"))

        node_trace = go.Scatter(x=[pos[n][0] for n in G.nodes()],
                                y=[pos[n][1] for n in G.nodes()],
                                mode='markers+text',
                                text=self.names, textposition="top center",
                                marker=dict(size=[d['size']/5 for n, d in G.nodes(data=True)],
                                            color=['#FF6B6B', '#4ECDC4', '#45B7D1']),
                                hoverinfo='none')

        fig = go.Figure(data=edge_traces + [node_trace],
                        layout=go.Layout(title='V2: ãƒãƒ¼ãƒ ç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', showlegend=False,
                                         xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                         yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))
        return fig

    def generate_all_visualizations(self):
        """å…¨ã¦ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆãƒ»è¡¨ç¤º"""
        print("\nğŸ“Š V2: å¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­...")

        # V2ã§æ„å‘³ã‚’æŒã¤ã‚ˆã†ã«ãªã£ãŸã‚°ãƒ©ãƒ•ã‚’ä¸­å¿ƒã«å¯è¦–åŒ–
        self.create_synergy_heatmap().show()
        self.create_growth_trajectory().show()
        self.create_business_metrics_dashboard().show()
        self.create_shapley_value_chart().show()
        self.create_network_graph().show()

        print("âœ… V2: å…¨ã¦ã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

# å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ
viz_engine = VisualizationEngine(analysis_data, synergy_results, growth_solution,
                                 time_axis, business_forecast, shapley_values)
viz_engine.generate_all_visualizations()


# ===============================================================
# STEP 9: åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
# ===============================================================
# V2ã®åˆ†æçµæœã«åŸºã¥ã„ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

class ReportGenerator:
    def __init__(self, analysis_data, synergy_results, shapley_values):
        self.analysis_data = analysis_data
        self.synergy_results = synergy_results
        self.shapley_values = shapley_values
        self.names = list(analysis_data.keys())

    def generate_report(self):
        """åˆ†æçµæœã‚’ã¾ã¨ã‚ãŸã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_str = "# äººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆ V2 (ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ç‰ˆ)\n\n"

        # 1. ç·åˆã‚·ãƒŠã‚¸ãƒ¼åˆ†æ
        report_str += "## 1. ç·åˆã‚·ãƒŠã‚¸ãƒ¼åˆ†æ\n"
        synergy_df = pd.DataFrame(self.synergy_results['total_synergy'],
                                  columns=self.names, index=self.names)
        report_str += "ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªã‚¯ã‚¹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:\n"
        report_str += synergy_df.to_markdown() + "\n\n"

        # 2. ã‚¹ã‚­ãƒ«è£œå®Œæ€§åˆ†æ
        report_str += "## 2. ã‚¹ã‚­ãƒ«è£œå®Œæ€§åˆ†æï¼ˆæ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰\n"
        comp_df = pd.DataFrame(self.synergy_results['skill_complementarity'],
                               columns=self.names, index=self.names)
        report_str += "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å…¨ä½“ã®æ„å‘³çš„ãªè£œå®Œæ€§ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼ˆ1ã«è¿‘ã„ã»ã©è£œå®Œçš„ï¼‰:\n"
        report_str += comp_df.to_markdown() + "\n\n"

        # 3. ä¾¡å€¤è²¢çŒ®åº¦åˆ†æ
        report_str += "## 3. ä¾¡å€¤è²¢çŒ®åº¦åˆ†æï¼ˆã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ï¼‰\n"
        report_str += "ãƒãƒ¼ãƒ å…¨ä½“ã§å‰µå‡ºã•ã‚Œã‚‹ä¾¡å€¤ã«å¯¾ã™ã‚‹å„ãƒ¡ãƒ³ãƒãƒ¼ã®è²¢çŒ®åº¦ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:\n"
        for name, val in zip(self.names, self.shapley_values):
            report_str += f"- {name}: {val:.3f}\n"
        report_str += "\n"

        # 4. ç·æ‹¬
        report_str += "## 4. ç·æ‹¬\n"
        report_str += "æœ¬åˆ†æ(V2)ã¯ã€å„ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®æ„å‘³çš„ãªå†…å®¹ã‚’ç›´æ¥æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç¾å®Ÿã«å³ã—ãŸã‚·ãƒŠã‚¸ãƒ¼ã¨è²¢çŒ®åº¦ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚\n"
        report_str += "ç‰¹ã«ã€ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´ã§ã¯ãªãã€æ–‡ç« å…¨ä½“ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ‰ãˆãŸçµæœã§ã™ã€‚\n"

        return report_str

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¨è¡¨ç¤º
report_generator = ReportGenerator(analysis_data, synergy_results, shapley_values)
final_report = report_generator.generate_report()
print("\nğŸ“‹ V2: åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n" + "="*50)
print(final_report)

# ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
filename = f"/content/drive/MyDrive/synergy_analysis_report_V2_{timestamp}.md"
try:
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(final_report)
    print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {filename}")
except Exception as e:
    print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


print("\n\nğŸŠ å…¨ã¦ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼ ğŸŠ")
