{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kX8sQdeG6M5Q"},"outputs":[],"source":["# ================================================================\n","# äººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ  - Google Colabå®Œå…¨å®Ÿè¡Œç‰ˆ\n","# å¯¾è±¡: Arale Cohen, Yanay Geva, Yasuyuki Sakane\n","# ================================================================\n","\n","# ================================================================\n","# STEP 1: å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š\n","# ================================================================\n","\n","# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n","!pip install networkx matplotlib seaborn plotly kaleido\n","!pip install scikit-learn pandas numpy scipy\n","!pip install wordcloud textblob vaderSentiment\n","!pip install torch torchvision --quiet\n","!pip install transformers --quiet\n","\n","# Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆ\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import networkx as nx\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# æ•°å­¦ãƒ»çµ±è¨ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n","from scipy import stats\n","from scipy.optimize import minimize\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# NLPé–¢é€£\n","from textblob import TextBlob\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","from wordcloud import WordCloud\n","\n","# ãã®ä»–\n","import json\n","import re\n","from datetime import datetime, timedelta\n","import random\n","from collections import Counter\n","import itertools\n","\n","print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","# ================================================================\n","# STEP 2: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ã®å®šç¾©\n","# ================================================================\n","\n","def load_profile_data():\n","    \"\"\"\n","    Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\n","    ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æƒ³å®š:\n","    - arale_cohen_profile.txt\n","    - yanay_geva_profile.txt\n","    - yasuyuki_sakane_profile.txt\n","    \"\"\"\n","\n","    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰\n","    base_path = \"/content/drive/MyDrive/\"\n","\n","    profiles = {}\n","    names = [\"arale_cohen\", \"yanay_geva\", \"yasuyuki_sakane\"]\n","    display_names = [\"Arale Cohen\", \"Yanay Geva\", \"Yasuyuki Sakane\"]\n","\n","    for name, display_name in zip(names, display_names):\n","        try:\n","            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n","            with open(f\"{base_path}{name}_profile.txt\", 'r', encoding='utf-8') as f:\n","                content = f.read()\n","            profiles[display_name] = content\n","            print(f\"âœ… {display_name}ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n","        except FileNotFoundError:\n","            print(f\"âš ï¸ {name}_profile.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™\")\n","            profiles[display_name] = generate_sample_profile(display_name)\n","\n","    return profiles\n","\n","def generate_sample_profile(name):\n","    \"\"\"ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆï¼‰\"\"\"\n","\n","    sample_profiles = {\n","        \"Arale Cohen\": \"\"\"\n","        Senior Technology Executive with 15+ years of experience in AI/ML and product development.\n","        Former Google AI Research Engineer, specialized in natural language processing and computer vision.\n","        Led multiple successful product launches with $100M+ revenue impact.\n","        PhD in Computer Science from Stanford University.\n","        Expertise: Machine Learning, Deep Learning, Product Strategy, Team Leadership\n","        Published 25+ research papers in top-tier conferences.\n","        Fluent in English, Hebrew, and basic Japanese.\n","        Strong network in Silicon Valley tech ecosystem.\n","        \"\"\",\n","\n","        \"Yanay Geva\": \"\"\"\n","        Seasoned Venture Capital Partner with 12+ years in technology investments.\n","        Former McKinsey & Company consultant with expertise in digital transformation.\n","        Successfully invested in 50+ startups with 8 unicorn exits.\n","        MBA from Wharton School, BS in Engineering from Technion.\n","        Expertise: Venture Capital, Strategic Planning, Market Analysis, Due Diligence\n","        Board member of 15+ technology companies.\n","        Strong network in global VC ecosystem and enterprise customers.\n","        Fluent in English, Hebrew, and conversational German.\n","        \"\"\",\n","\n","        \"Yasuyuki Sakane\": \"\"\"\n","        Technology Innovation Leader with 18+ years in Japan's tech industry.\n","        Former CTO of major Japanese fintech company, led 200+ engineering team.\n","        Expert in blockchain, cryptocurrency, and financial technology.\n","        MS in Computer Science from University of Tokyo.\n","        Expertise: Blockchain Technology, Fintech, System Architecture, Cross-cultural Management\n","        Successfully launched multiple products in Japanese and Asian markets.\n","        Deep understanding of Japanese business culture and regulatory environment.\n","        Fluent in Japanese, English, and basic Mandarin.\n","        Extensive network in Japan's tech and financial sectors.\n","        \"\"\"\n","    }\n","\n","    return sample_profiles.get(name, \"Profile data not available\")\n","\n","# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Ÿè¡Œ\n","profiles = load_profile_data()\n","\n","# ================================================================\n","# STEP 3: ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æã¨ç‰¹å¾´æŠ½å‡º\n","# ================================================================\n","\n","class ProfileAnalyzer:\n","    def __init__(self, profiles):\n","        self.profiles = profiles\n","        self.names = list(profiles.keys())\n","        self.analyzer = SentimentIntensityAnalyzer()\n","\n","    def extract_skills(self, text):\n","        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¹ã‚­ãƒ«ãƒ»å°‚é–€åˆ†é‡ã‚’æŠ½å‡º\"\"\"\n","        # æŠ€è¡“ãƒ»ãƒ“ã‚¸ãƒã‚¹ã‚¹ã‚­ãƒ«ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸\n","        skill_keywords = {\n","            'AI/ML': ['artificial intelligence', 'machine learning', 'deep learning', 'neural network', 'ai', 'ml'],\n","            'Technology': ['technology', 'tech', 'engineering', 'software', 'system', 'architecture'],\n","            'Finance': ['finance', 'fintech', 'venture capital', 'investment', 'funding', 'vc'],\n","            'Leadership': ['leadership', 'management', 'team', 'cto', 'ceo', 'executive', 'director'],\n","            'Product': ['product', 'development', 'launch', 'strategy', 'planning'],\n","            'Research': ['research', 'phd', 'published', 'papers', 'conference'],\n","            'International': ['global', 'international', 'cross-cultural', 'multilingual', 'fluent'],\n","            'Blockchain': ['blockchain', 'cryptocurrency', 'crypto', 'bitcoin', 'defi'],\n","            'Data': ['data', 'analytics', 'analysis', 'insight', 'intelligence']\n","        }\n","\n","        text_lower = text.lower()\n","        skills = {}\n","\n","        for category, keywords in skill_keywords.items():\n","            score = sum(text_lower.count(keyword) for keyword in keywords)\n","            skills[category] = min(score * 10, 100)  # 0-100ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–\n","\n","        return skills\n","\n","    def extract_experience_years(self, text):\n","        \"\"\"çµŒé¨“å¹´æ•°ã‚’æŠ½å‡º\"\"\"\n","        # å¹´æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢\n","        patterns = [r'(\\d+)\\+?\\s*years?', r'(\\d+)\\+?\\s*year']\n","        years = []\n","\n","        for pattern in patterns:\n","            matches = re.findall(pattern, text.lower())\n","            years.extend([int(match) for match in matches])\n","\n","        return max(years) if years else 10  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤\n","\n","    def extract_network_strength(self, text):\n","        \"\"\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦ã‚’æ¨å®š\"\"\"\n","        network_indicators = [\n","            'network', 'ecosystem', 'connections', 'board member',\n","            'partner', 'collaboration', 'global', 'silicon valley'\n","        ]\n","\n","        text_lower = text.lower()\n","        score = sum(text_lower.count(indicator) for indicator in network_indicators)\n","        return min(score * 15, 100)  # 0-100ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–\n","\n","    def analyze_all_profiles(self):\n","        \"\"\"å…¨ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’åˆ†æ\"\"\"\n","        analysis_results = {}\n","\n","        for name, profile in self.profiles.items():\n","            skills = self.extract_skills(profile)\n","            experience = self.extract_experience_years(profile)\n","            network = self.extract_network_strength(profile)\n","            sentiment = self.analyzer.polarity_scores(profile)\n","\n","            analysis_results[name] = {\n","                'skills': skills,\n","                'experience_years': experience,\n","                'network_strength': network,\n","                'sentiment': sentiment['compound'],\n","                'profile_length': len(profile.split()),\n","                'raw_profile': profile\n","            }\n","\n","        return analysis_results\n","\n","# ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æå®Ÿè¡Œ\n","analyzer = ProfileAnalyzer(profiles)\n","analysis_data = analyzer.analyze_all_profiles()\n","\n","print(\"âœ… ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","# ================================================================\n","# STEP 4: ç›¸äº’ä½œç”¨ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—\n","# ================================================================\n","\n","class SynergyCalculator:\n","    def __init__(self, analysis_data):\n","        self.data = analysis_data\n","        self.names = list(analysis_data.keys())\n","\n","    def calculate_skill_complementarity(self):\n","        \"\"\"ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã‚’è¨ˆç®—\"\"\"\n","        skill_matrix = []\n","\n","        for name in self.names:\n","            skills = list(self.data[name]['skills'].values())\n","            skill_matrix.append(skills)\n","\n","        skill_matrix = np.array(skill_matrix)\n","\n","        # ã‚¹ã‚­ãƒ«è£œå®Œæ€§ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆä½ã„é¡ä¼¼åº¦ = é«˜ã„è£œå®Œæ€§ï¼‰\n","        similarity_matrix = cosine_similarity(skill_matrix)\n","        complementarity_matrix = 1 - similarity_matrix\n","\n","        return complementarity_matrix, skill_matrix\n","\n","    def calculate_experience_synergy(self):\n","        \"\"\"çµŒé¨“ã‚·ãƒŠã‚¸ãƒ¼ã‚’è¨ˆç®—\"\"\"\n","        experiences = [self.data[name]['experience_years'] for name in self.names]\n","\n","        # çµŒé¨“å¹´æ•°ã®å·®ã«ã‚ˆã‚‹ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ\n","        synergy_matrix = np.zeros((3, 3))\n","\n","        for i in range(3):\n","            for j in range(3):\n","                if i != j:\n","                    # çµŒé¨“å·®ãŒé©åº¦ãªå ´åˆã«ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœãŒé«˜ã„\n","                    exp_diff = abs(experiences[i] - experiences[j])\n","                    if 2 <= exp_diff <= 8:\n","                        synergy_matrix[i][j] = 1.0 - (exp_diff - 2) / 6\n","                    elif exp_diff < 2:\n","                        synergy_matrix[i][j] = 0.8  # é¡ä¼¼çµŒé¨“ã§ã‚‚ä¸€å®šã®ã‚·ãƒŠã‚¸ãƒ¼\n","                    else:\n","                        synergy_matrix[i][j] = 0.3  # å¤§ããªå·®ã§ã‚‚æœ€å°é™ã®ã‚·ãƒŠã‚¸ãƒ¼\n","\n","        return synergy_matrix, experiences\n","\n","    def calculate_network_effects(self):\n","        \"\"\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹æœã‚’è¨ˆç®—\"\"\"\n","        networks = [self.data[name]['network_strength'] for name in self.names]\n","\n","        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµåˆåŠ¹æœï¼ˆãƒ¡ãƒˆã‚«ãƒ¼ãƒ•ã®æ³•å‰‡ï¼‰\n","        network_matrix = np.zeros((3, 3))\n","\n","        for i in range(3):\n","            for j in range(3):\n","                if i != j:\n","                    # ä¸¡è€…ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦ã®ç©ï¼ˆéç·šå½¢åŠ¹æœï¼‰\n","                    combined_strength = (networks[i] * networks[j]) / 10000  # æ­£è¦åŒ–\n","                    network_matrix[i][j] = combined_strength\n","\n","        return network_matrix, networks\n","\n","    def calculate_cultural_diversity_bonus(self):\n","        \"\"\"æ–‡åŒ–çš„å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹ã‚’è¨ˆç®—\"\"\"\n","        # åå‰ã‹ã‚‰æ–‡åŒ–çš„èƒŒæ™¯ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰\n","        cultural_backgrounds = {\n","            'Arale Cohen': 'Israeli/Western',\n","            'Yanay Geva': 'Israeli/Western',\n","            'Yasuyuki Sakane': 'Japanese/Eastern'\n","        }\n","\n","        diversity_matrix = np.zeros((3, 3))\n","\n","        for i, name1 in enumerate(self.names):\n","            for j, name2 in enumerate(self.names):\n","                if i != j:\n","                    bg1 = cultural_backgrounds[name1]\n","                    bg2 = cultural_backgrounds[name2]\n","\n","                    # ç•°ãªã‚‹æ–‡åŒ–èƒŒæ™¯ã®å ´åˆã¯ãƒœãƒ¼ãƒŠã‚¹\n","                    if 'Eastern' in bg1 and 'Western' in bg2:\n","                        diversity_matrix[i][j] = 1.5\n","                    elif 'Western' in bg1 and 'Eastern' in bg2:\n","                        diversity_matrix[i][j] = 1.5\n","                    else:\n","                        diversity_matrix[i][j] = 1.0\n","\n","        return diversity_matrix\n","\n","    def calculate_total_synergy_matrix(self):\n","        \"\"\"ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—\"\"\"\n","        comp_matrix, skill_matrix = self.calculate_skill_complementarity()\n","        exp_matrix, experiences = self.calculate_experience_synergy()\n","        net_matrix, networks = self.calculate_network_effects()\n","        div_matrix = self.calculate_cultural_diversity_bonus()\n","\n","        # é‡ã¿ä»˜ãçµ±åˆï¼ˆèª¿æ•´å¯èƒ½ï¼‰\n","        weights = {\n","            'complementarity': 0.3,\n","            'experience': 0.25,\n","            'network': 0.25,\n","            'diversity': 0.2\n","        }\n","\n","        total_synergy = (\n","            weights['complementarity'] * comp_matrix +\n","            weights['experience'] * exp_matrix +\n","            weights['network'] * net_matrix +\n","            weights['diversity'] * div_matrix\n","        )\n","\n","        return {\n","            'total_synergy': total_synergy,\n","            'skill_complementarity': comp_matrix,\n","            'experience_synergy': exp_matrix,\n","            'network_effects': net_matrix,\n","            'diversity_bonus': div_matrix,\n","            'skill_matrix': skill_matrix,\n","            'experiences': experiences,\n","            'networks': networks\n","        }\n","\n","# ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—å®Ÿè¡Œ\n","synergy_calc = SynergyCalculator(analysis_data)\n","synergy_results = synergy_calc.calculate_total_synergy_matrix()\n","\n","print(\"âœ… ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","# ================================================================\n","# STEP 5: å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n","# ================================================================\n","\n","class DynamicSystemModel:\n","    def __init__(self, synergy_results, analysis_data):\n","        self.synergy_matrix = synergy_results['total_synergy']\n","        self.data = analysis_data\n","        self.names = list(analysis_data.keys())\n","\n","    def define_system_parameters(self):\n","        \"\"\"ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©\"\"\"\n","        # å€‹äººæˆé•·ç‡ï¼ˆÎ±ï¼‰\n","        alpha = np.array([0.05, 0.04, 0.06])  # Arale, Yanay, Yasuyuki\n","\n","        # ç›¸äº’ä½œç”¨ä¿‚æ•°ï¼ˆÎ²ï¼‰\n","        beta = self.synergy_matrix * 0.1  # ã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‹ã‚‰å°å‡º\n","\n","        # éç·šå½¢ã‚·ãƒŠã‚¸ãƒ¼ä¿‚æ•°ï¼ˆÎ´, Îµï¼‰\n","        delta = self.synergy_matrix * 0.02\n","        epsilon = self.synergy_matrix * 0.015\n","\n","        return alpha, beta, delta, epsilon\n","\n","    def system_dynamics(self, state, t, alpha, beta, delta, epsilon):\n","        \"\"\"å‹•çš„ã‚·ã‚¹ãƒ†ãƒ æ–¹ç¨‹å¼\"\"\"\n","        x1, x2, x3 = state\n","\n","        dx1dt = (alpha[0] * x1 +\n","                beta[0,1] * x2 + beta[0,2] * x3 +\n","                delta[0,1] * x1 * x2 + epsilon[0,2] * x1 * x3)\n","\n","        dx2dt = (alpha[1] * x2 +\n","                beta[1,0] * x1 + beta[1,2] * x3 +\n","                delta[1,0] * x1 * x2 + epsilon[1,2] * x2 * x3)\n","\n","        dx3dt = (alpha[2] * x3 +\n","                beta[2,0] * x1 + beta[2,1] * x2 +\n","                delta[2,0] * x1 * x3 + epsilon[2,1] * x2 * x3)\n","\n","        return [dx1dt, dx2dt, dx3dt]\n","\n","    def simulate_growth(self, initial_state=None, time_horizon=24):\n","        \"\"\"æˆé•·ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ\"\"\"\n","        from scipy.integrate import odeint\n","\n","        # åˆæœŸçŠ¶æ…‹è¨­å®šï¼ˆçµŒé¨“ã¨ã‚¹ã‚­ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰\n","        if initial_state is None:\n","            initial_state = [\n","                self.data[self.names[0]]['experience_years'] / 20,  # æ­£è¦åŒ–\n","                self.data[self.names[1]]['experience_years'] / 20,\n","                self.data[self.names[2]]['experience_years'] / 20\n","            ]\n","\n","        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—\n","        alpha, beta, delta, epsilon = self.define_system_parameters()\n","\n","        # æ™‚é–“è»¸è¨­å®šï¼ˆæœˆå˜ä½ï¼‰\n","        t = np.linspace(0, time_horizon, time_horizon * 4)  # é€±å˜ä½ã®è§£åƒåº¦\n","\n","        # ã‚·ã‚¹ãƒ†ãƒ è§£æ±º\n","        solution = odeint(self.system_dynamics, initial_state, t,\n","                         args=(alpha, beta, delta, epsilon))\n","\n","        return t, solution, (alpha, beta, delta, epsilon)\n","\n","    def calculate_compound_growth_rate(self, solution):\n","        \"\"\"è¤‡åˆ©æˆé•·ç‡ã‚’è¨ˆç®—\"\"\"\n","        growth_rates = []\n","\n","        for i in range(3):\n","            initial_value = solution[0, i]\n","            final_value = solution[-1, i]\n","            time_period = len(solution) / 4  # å¹´æ•°ã«å¤‰æ›\n","\n","            if initial_value > 0:\n","                compound_rate = (final_value / initial_value) ** (1/time_period) - 1\n","                growth_rates.append(compound_rate * 100)  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨ç¤º\n","            else:\n","                growth_rates.append(0)\n","\n","        return growth_rates\n","\n","# å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ\n","dynamic_model = DynamicSystemModel(synergy_results, analysis_data)\n","time_axis, growth_solution, system_params = dynamic_model.simulate_growth()\n","compound_rates = dynamic_model.calculate_compound_growth_rate(growth_solution)\n","\n","print(\"âœ… å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","# ================================================================\n","# STEP 6: ã‚²ãƒ¼ãƒ ç†è«–åˆ†æ\n","# ================================================================\n","\n","class GameTheoryAnalysis:\n","    def __init__(self, synergy_results, analysis_data):\n","        self.synergy_matrix = synergy_results['total_synergy']\n","        self.data = analysis_data\n","        self.names = list(analysis_data.keys())\n","\n","    def calculate_shapley_values(self):\n","        \"\"\"ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã«ã‚ˆã‚‹ä¾¡å€¤é…åˆ†è¨ˆç®—\"\"\"\n","\n","        def coalition_value(coalition):\n","            \"\"\"é€£åˆã®ä¾¡å€¤é–¢æ•°\"\"\"\n","            if len(coalition) == 0:\n","                return 0\n","            elif len(coalition) == 1:\n","                idx = coalition[0]\n","                base_value = (self.data[self.names[idx]]['experience_years'] +\n","                            self.data[self.names[idx]]['network_strength']) / 20\n","                return base_value\n","            else:\n","                # é€£åˆã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ\n","                base_sum = sum(self.coalition_value([i]) for i in coalition)\n","                synergy_bonus = 0\n","\n","                for i in coalition:\n","                    for j in coalition:\n","                        if i != j:\n","                            synergy_bonus += self.synergy_matrix[i, j]\n","\n","                return base_sum + synergy_bonus * 0.5\n","\n","        self.coalition_value = coalition_value\n","\n","        # ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤è¨ˆç®—\n","        n = 3\n","        shapley_values = [0, 0, 0]\n","\n","        for i in range(n):\n","            for coalition_size in range(0, n):\n","                # ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼iä»¥å¤–ã®å…¨ã¦ã®éƒ¨åˆ†é›†åˆã‚’è€ƒæ…®\n","                other_players = [j for j in range(n) if j != i]\n","\n","                from itertools import combinations\n","                for coalition in combinations(other_players, coalition_size):\n","                    coalition = list(coalition)\n","\n","                    # è²¢çŒ®åº¦è¨ˆç®—\n","                    value_with_i = coalition_value(coalition + [i])\n","                    value_without_i = coalition_value(coalition)\n","                    marginal_contribution = value_with_i - value_without_i\n","\n","                    # ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã¸ã®å¯„ä¸\n","                    coefficient = (np.math.factorial(coalition_size) *\n","                                  np.math.factorial(n - coalition_size - 1) /\n","                                  np.math.factorial(n))\n","\n","                    shapley_values[i] += coefficient * marginal_contribution\n","\n","        return shapley_values\n","\n","    def find_nash_equilibrium(self):\n","        \"\"\"ãƒŠãƒƒã‚·ãƒ¥å‡è¡¡ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰\"\"\"\n","\n","        # å„ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æˆ¦ç•¥ç©ºé–“ï¼ˆå”åŠ›ãƒ¬ãƒ™ãƒ« 0-1ï¼‰\n","        strategies = np.linspace(0, 1, 11)\n","\n","        # åˆ©å¾—ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¨ˆç®—\n","        best_responses = []\n","\n","        for player in range(3):\n","            best_response = []\n","\n","            for s1 in strategies:\n","                for s2 in strategies:\n","                    # ä»–ã®ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æˆ¦ç•¥ã«å¯¾ã™ã‚‹æœ€é©å¿œç­”\n","                    others_strategies = [s1, s2]\n","                    others_strategies.pop(player if player < 2 else 1)\n","\n","                    max_payoff = -float('inf')\n","                    best_strategy = 0\n","\n","                    for own_strategy in strategies:\n","                        # åˆ©å¾—è¨ˆç®—ï¼ˆç°¡ç•¥åŒ–ï¼‰\n","                        payoff = self.calculate_payoff(player, own_strategy, others_strategies)\n","\n","                        if payoff > max_payoff:\n","                            max_payoff = payoff\n","                            best_strategy = own_strategy\n","\n","                    best_response.append(best_strategy)\n","\n","            best_responses.append(best_response)\n","\n","        # è¿‘ä¼¼ãƒŠãƒƒã‚·ãƒ¥å‡è¡¡ç‚¹\n","        equilibrium_strategies = [np.mean(br) for br in best_responses]\n","\n","        return equilibrium_strategies\n","\n","    def calculate_payoff(self, player, own_strategy, others_strategies):\n","        \"\"\"ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®åˆ©å¾—ã‚’è¨ˆç®—\"\"\"\n","        base_payoff = own_strategy * self.data[self.names[player]]['experience_years'] / 10\n","\n","        # ä»–ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ\n","        synergy_payoff = 0\n","        for i, other_strategy in enumerate(others_strategies):\n","            other_player = i if i < player else i + 1\n","            synergy_payoff += (own_strategy * other_strategy *\n","                             self.synergy_matrix[player, other_player])\n","\n","        return base_payoff + synergy_payoff\n","\n","# ã‚²ãƒ¼ãƒ ç†è«–åˆ†æå®Ÿè¡Œ\n","game_analysis = GameTheoryAnalysis(synergy_results, analysis_data)\n","shapley_values = game_analysis.calculate_shapley_values()\n","nash_equilibrium = game_analysis.find_nash_equilibrium()\n","\n","print(\"âœ… ã‚²ãƒ¼ãƒ ç†è«–åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","# ================================================================\n","# STEP 7: äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n","# ================================================================\n","\n","class PredictionModel:\n","    def __init__(self, growth_solution, time_axis, synergy_results):\n","        self.growth_data = growth_solution\n","        self.time_axis = time_axis\n","        self.synergy_matrix = synergy_results['total_synergy']\n","\n","    def forecast_business_metrics(self):\n","        \"\"\"ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™äºˆæ¸¬\"\"\"\n","\n","        # æˆé•·ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¥­ç¸¾æŒ‡æ¨™ã‚’æ¨å®š\n","        performance_data = []\n","\n","        for t in range(len(self.time_axis)):\n","            # å„æ™‚ç‚¹ã§ã®ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n","            individual_performance = self.growth_data[t]\n","            team_synergy = np.sum(self.synergy_matrix) * np.prod(individual_performance)\n","\n","            # ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™æ¨å®š\n","            revenue_growth = (np.sum(individual_performance) + team_synergy) * 100\n","            innovation_index = team_synergy * 150\n","            market_share = min(team_synergy * 80, 25)  # æœ€å¤§25%\n","            customer_satisfaction = 70 + team_synergy * 20\n","\n","            performance_data.append({\n","                'time_months': self.time_axis[t],\n","                'revenue_growth_rate': revenue_growth,\n","                'innovation_index': innovation_index,\n","                'market_share_percent': market_share,\n","                'customer_satisfaction': min(customer_satisfaction, 100)\n","            })\n","\n","        return pd.DataFrame(performance_data)\n","\n","    def monte_carlo_simulation(self, n_simulations=1000):\n","        \"\"\"ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\"\"\"\n","\n","        simulation_results = []\n","\n","        for sim in range(n_simulations):\n","            # ãƒ©ãƒ³ãƒ€ãƒ ãªè¦å› ã‚’è¿½åŠ \n","            noise_factor = np.random.normal(1, 0.1, len(self.time_axis))\n","            market_shock = np.random.choice([0.8, 0.9, 1.0, 1.1, 1.2],\n","                                          size=len(self.time_axis),\n","                                          p=[0.1, 0.2, 0.4, 0.2, 0.1])\n","\n","            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ\n","            simulated_growth = self.growth_data * noise_factor.reshape(-1, 1) * market_shock.reshape(-1, 1)\n","\n","            # æœ€çµ‚æˆæœæŒ‡æ¨™\n","            final_performance = np.sum(simulated_growth[-1])\n","            total_synergy = np.sum(self.synergy_matrix) * np.prod(simulated_growth[-1])\n","\n","            simulation_results.append({\n","                'final_performance': final_performance,\n","                'total_synergy': total_synergy,\n","                'success_probability': 1 if final_performance > np.sum(self.growth_data[0]) * 1.5 else 0\n","            })\n","\n","        return pd.DataFrame(simulation_results)\n","\n","    def calculate_roi_metrics(self, investment_cost=1000000):  # 100ä¸‡ãƒ‰ãƒ«æƒ³å®š\n","        \"\"\"ROIæŒ‡æ¨™è¨ˆç®—\"\"\"\n","\n","        performance_df = self.forecast_business_metrics()\n","\n","        # ç´¯ç©åç›Šè¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰\n","        monthly_revenue = performance_df['revenue_growth_rate'] * 10000  # å£²ä¸Šè¦æ¨¡æƒ³å®š\n","        cumulative_revenue = monthly_revenue.cumsum()\n","\n","        # ROIè¨ˆç®—\n","        roi_over_time = (cumulative_revenue - investment_cost) / investment_cost * 100\n","\n","        # æŠ•è³‡å›åæœŸé–“\n","        payback_period = None\n","        for i, cum_rev in enumerate(cumulative_revenue):\n","            if cum_rev >= investment_cost:\n","                payback_period = performance_df.loc[i, 'time_months']\n","                break\n","\n","        # NPVè¨ˆç®—ï¼ˆå‰²å¼•ç‡5%æƒ³å®šï¼‰\n","        discount_rate = 0.05 / 12  # æœˆæ¬¡å‰²å¼•ç‡\n","        npv = sum(monthly_revenue.iloc[i] / (1 + discount_rate)**i\n","                 for i in range(len(monthly_revenue))) - investment_cost\n","\n","        return {\n","            'performance_df': performance_df,\n","            'roi_over_time': roi_over_time,\n","            'payback_period_months': payback_period,\n","            'npv': npv,\n","            'final_roi_percent': roi_over_time.iloc[-1] if len(roi_over_time) > 0 else 0\n","        }\n","\n","# äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å®Ÿè¡Œ\n","prediction_model = PredictionModel(growth_solution, time_axis, synergy_results)\n","business_forecast = prediction_model.forecast_business_metrics()\n","monte_carlo_results = prediction_model.monte_carlo_simulation()\n","roi_metrics = prediction_model.calculate_roi_metrics()\n","\n","print(\"âœ… äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","# ================================================================\n","# STEP 8: å¯è¦–åŒ–ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n","# ================================================================\n","\n","class VisualizationEngine:\n","    def __init__(self, analysis_data, synergy_results, growth_solution,\n","                 time_axis, business_forecast, shapley_values, nash_equilibrium,\n","                 monte_carlo_results, roi_metrics):\n","\n","        self.analysis_data = analysis_data\n","        self.synergy_results = synergy_results\n","        self.growth_solution = growth_solution\n","        self.time_axis = time_axis\n","        self.business_forecast = business_forecast\n","        self.shapley_values = shapley_values\n","        self.nash_equilibrium = nash_equilibrium\n","        self.monte_carlo_results = monte_carlo_results\n","        self.roi_metrics = roi_metrics\n","        self.names = list(analysis_data.keys())\n","\n","    def create_skill_radar_chart(self):\n","        \"\"\"ã‚¹ã‚­ãƒ«ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆä½œæˆ\"\"\"\n","\n","        # ã‚¹ã‚­ãƒ«ã‚«ãƒ†ã‚´ãƒªå–å¾—\n","        skill_categories = list(self.analysis_data[self.names[0]]['skills'].keys())\n","\n","        fig = go.Figure()\n","\n","        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n","\n","        for i, name in enumerate(self.names):\n","            skills = list(self.analysis_data[name]['skills'].values())\n","\n","            fig.add_trace(go.Scatterpolar(\n","                r=skills,\n","                theta=skill_categories,\n","                fill='toself',\n","                name=name,\n","                line_color=colors[i],\n","                fillcolor=colors[i],\n","                opacity=0.3\n","            ))\n","\n","        fig.update_layout(\n","            polar=dict(\n","                radialaxis=dict(\n","                    visible=True,\n","                    range=[0, 100]\n","                )),\n","            showlegend=True,\n","            title=\"å€‹äººã‚¹ã‚­ãƒ«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ¯”è¼ƒ\",\n","            font=dict(size=14),\n","            height=600\n","        )\n","\n","        return fig\n","\n","    def create_synergy_heatmap(self):\n","        \"\"\"ã‚·ãƒŠã‚¸ãƒ¼ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ\"\"\"\n","\n","        fig = go.Figure(data=go.Heatmap(\n","            z=self.synergy_results['total_synergy'],\n","            x=self.names,\n","            y=self.names,\n","            colorscale='RdYlBu_r',\n","            text=np.round(self.synergy_results['total_synergy'], 3),\n","            texttemplate=\"%{text}\",\n","            textfont={\"size\": 12},\n","            hoverongaps=False\n","        ))\n","\n","        fig.update_layout(\n","            title=\"ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹\",\n","            xaxis_title=\"\",\n","            yaxis_title=\"\",\n","            font=dict(size=14),\n","            height=500\n","        )\n","\n","        return fig\n","\n","    def create_growth_trajectory(self):\n","        \"\"\"æˆé•·è»Œé“å¯è¦–åŒ–\"\"\"\n","\n","        fig = go.Figure()\n","\n","        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n","\n","        for i, name in enumerate(self.names):\n","            fig.add_trace(go.Scatter(\n","                x=self.time_axis,\n","                y=self.growth_solution[:, i],\n","                mode='lines+markers',\n","                name=name,\n","                line=dict(color=colors[i], width=3),\n","                marker=dict(size=6)\n","            ))\n","\n","        fig.update_layout(\n","            title=\"å‹•çš„æˆé•·è»Œé“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\",\n","            xaxis_title=\"æ™‚é–“ï¼ˆæœˆï¼‰\",\n","            yaxis_title=\"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ•°\",\n","            font=dict(size=14),\n","            height=500,\n","            hovermode='x unified'\n","        )\n","\n","        return fig\n","\n","    def create_business_metrics_dashboard(self):\n","        \"\"\"ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰\"\"\"\n","\n","        fig = make_subplots(\n","            rows=2, cols=2,\n","            subplot_titles=('å£²ä¸Šæˆé•·ç‡', 'ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°',\n","                          'ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢', 'é¡§å®¢æº€è¶³åº¦'),\n","            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n","                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n","        )\n","\n","        # å£²ä¸Šæˆé•·ç‡\n","        fig.add_trace(\n","            go.Scatter(x=self.business_forecast['time_months'],\n","                      y=self.business_forecast['revenue_growth_rate'],\n","                      name='å£²ä¸Šæˆé•·ç‡', line=dict(color='#FF6B6B')),\n","            row=1, col=1\n","        )\n","\n","        # ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°\n","        fig.add_trace(\n","            go.Scatter(x=self.business_forecast['time_months'],\n","                      y=self.business_forecast['innovation_index'],\n","                      name='ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°', line=dict(color='#4ECDC4')),\n","            row=1, col=2\n","        )\n","\n","        # ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢\n","        fig.add_trace(\n","            go.Scatter(x=self.business_forecast['time_months'],\n","                      y=self.business_forecast['market_share_percent'],\n","                      name='ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢', line=dict(color='#45B7D1')),\n","            row=2, col=1\n","        )\n","\n","        # é¡§å®¢æº€è¶³åº¦\n","        fig.add_trace(\n","            go.Scatter(x=self.business_forecast['time_months'],\n","                      y=self.business_forecast['customer_satisfaction'],\n","                      name='é¡§å®¢æº€è¶³åº¦', line=dict(color='#F7DC6F')),\n","            row=2, col=2\n","        )\n","\n","        fig.update_layout(\n","            title=\"ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰\",\n","            height=800,\n","            showlegend=False,\n","            font=dict(size=12)\n","        )\n","\n","        return fig\n","\n","    def create_monte_carlo_distribution(self):\n","        \"\"\"ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­çµæœåˆ†å¸ƒ\"\"\"\n","\n","        fig = make_subplots(\n","            rows=1, cols=2,\n","            subplot_titles=('æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ', 'ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœåˆ†å¸ƒ')\n","        )\n","\n","        # æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ\n","        fig.add_trace(\n","            go.Histogram(x=self.monte_carlo_results['final_performance'],\n","                        name='æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹',\n","                        nbinsx=30, opacity=0.7),\n","            row=1, col=1\n","        )\n","\n","        # ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœåˆ†å¸ƒ\n","        fig.add_trace(\n","            go.Histogram(x=self.monte_carlo_results['total_synergy'],\n","                        name='ç·ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ',\n","                        nbinsx=30, opacity=0.7),\n","            row=1, col=2\n","        )\n","\n","        fig.update_layout(\n","            title=\"ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœåˆ†å¸ƒ\",\n","            height=500,\n","            font=dict(size=14)\n","        )\n","\n","        return fig\n","\n","    def create_roi_analysis(self):\n","        \"\"\"ROIåˆ†æãƒãƒ£ãƒ¼ãƒˆ\"\"\"\n","\n","        fig = make_subplots(\n","            rows=1, cols=2,\n","            subplot_titles=('ROIæ¨ç§»', 'ç´¯ç©åç›Š')\n","        )\n","\n","        # ROIæ¨ç§»\n","        fig.add_trace(\n","            go.Scatter(x=self.business_forecast['time_months'],\n","                      y=self.roi_metrics['roi_over_time'],\n","                      name='ROI (%)', line=dict(color='#2ECC71', width=3)),\n","            row=1, col=1\n","        )\n","\n","        # ç´¯ç©åç›Š\n","        monthly_revenue = self.business_forecast['revenue_growth_rate'] * 10000\n","        cumulative_revenue = monthly_revenue.cumsum()\n","\n","        fig.add_trace(\n","            go.Scatter(x=self.business_forecast['time_months'],\n","                      y=cumulative_revenue,\n","                      name='ç´¯ç©åç›Š', line=dict(color='#E74C3C', width=3)),\n","            row=1, col=2\n","        )\n","\n","        fig.update_layout(\n","            title=\"ROIãƒ»åç›Šæ€§åˆ†æ\",\n","            height=500,\n","            font=dict(size=14)\n","        )\n","\n","        return fig\n","\n","    def create_shapley_value_chart(self):\n","        \"\"\"ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤å¯è¦–åŒ–\"\"\"\n","\n","        fig = go.Figure([go.Bar(\n","            x=self.names,\n","            y=self.shapley_values,\n","            text=[f'{val:.3f}' for val in self.shapley_values],\n","            textposition='auto',\n","            marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1']\n","        )])\n","\n","        fig.update_layout(\n","            title=\"ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã«ã‚ˆã‚‹ä¾¡å€¤è²¢çŒ®åº¦åˆ†æ\",\n","            xaxis_title=\"ãƒ¡ãƒ³ãƒãƒ¼\",\n","            yaxis_title=\"ä¾¡å€¤è²¢çŒ®åº¦\",\n","            font=dict(size=14),\n","            height=500\n","        )\n","\n","        return fig\n","\n","    def create_network_graph(self):\n","        \"\"\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ä½œæˆ\"\"\"\n","\n","        G = nx.Graph()\n","\n","        # ãƒãƒ¼ãƒ‰è¿½åŠ \n","        for i, name in enumerate(self.names):\n","            G.add_node(name,\n","                      size=self.analysis_data[name]['network_strength'],\n","                      experience=self.analysis_data[name]['experience_years'])\n","\n","        # ã‚¨ãƒƒã‚¸è¿½åŠ ï¼ˆã‚·ãƒŠã‚¸ãƒ¼å¼·åº¦ã«åŸºã¥ãï¼‰\n","        for i in range(len(self.names)):\n","            for j in range(i+1, len(self.names)):\n","                weight = self.synergy_results['total_synergy'][i, j]\n","                if weight > 0.5:  # é–¾å€¤ä»¥ä¸Šã®å ´åˆã®ã¿ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ \n","                    G.add_edge(self.names[i], self.names[j], weight=weight)\n","\n","        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—\n","        pos = nx.spring_layout(G, k=1, iterations=50)\n","\n","        # ã‚¨ãƒƒã‚¸æç”»\n","        edge_x = []\n","        edge_y = []\n","        edge_info = []\n","\n","        for edge in G.edges():\n","            x0, y0 = pos[edge[0]]\n","            x1, y1 = pos[edge[1]]\n","            edge_x.extend([x0, x1, None])\n","            edge_y.extend([y0, y1, None])\n","            weight = G[edge[0]][edge[1]]['weight']\n","            edge_info.append(f'{edge[0]} - {edge[1]}: {weight:.3f}')\n","\n","        edge_trace = go.Scatter(x=edge_x, y=edge_y,\n","                               line=dict(width=2, color='#888'),\n","                               hoverinfo='none',\n","                               mode='lines')\n","\n","        # ãƒãƒ¼ãƒ‰æç”»\n","        node_x = []\n","        node_y = []\n","        node_text = []\n","        node_size = []\n","\n","        for node in G.nodes():\n","            x, y = pos[node]\n","            node_x.append(x)\n","            node_y.append(y)\n","            node_text.append(f'{node}<br>Network: {G.nodes[node][\"size\"]}<br>Experience: {G.nodes[node][\"experience\"]}')\n","            node_size.append(G.nodes[node]['size'] / 2)\n","\n","        node_trace = go.Scatter(x=node_x, y=node_y,\n","                               mode='markers+text',\n","                               hoverinfo='text',\n","                               text=[name.split()[0] for name in self.names],\n","                               textposition=\"middle center\",\n","                               hovertext=node_text,\n","                               marker=dict(size=node_size,\n","                                         color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n","                                         line=dict(width=2, color='white')))\n","\n","        fig = go.Figure(data=[edge_trace, node_trace],\n","                       layout=go.Layout(\n","                        title='ãƒãƒ¼ãƒ ç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯',\n","                        titlefont_size=16,\n","                        showlegend=False,\n","                        hovermode='closest',\n","                        margin=dict(b=20,l=5,r=5,t=40),\n","                        annotations=[ dict(\n","                            text=\"ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦<br>ã‚¨ãƒƒã‚¸å¤ªã•: ã‚·ãƒŠã‚¸ãƒ¼å¼·åº¦\",\n","                            showarrow=False,\n","                            xref=\"paper\", yref=\"paper\",\n","                            x=0.005, y=-0.002,\n","                            xanchor=\"left\", yanchor=\"bottom\",\n","                            font=dict(color=\"#000000\", size=12)\n","                        )],\n","                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n","                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n","                        height=600))\n","\n","        return fig\n","\n","    def generate_all_visualizations(self):\n","        \"\"\"å…¨ã¦ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆ\"\"\"\n","\n","        print(\"ğŸ“Š å¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­...\")\n","\n","        # å„ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ\n","        skill_radar = self.create_skill_radar_chart()\n","        synergy_heatmap = self.create_synergy_heatmap()\n","        growth_trajectory = self.create_growth_trajectory()\n","        business_dashboard = self.create_business_metrics_dashboard()\n","        monte_carlo_dist = self.create_monte_carlo_distribution()\n","        roi_analysis = self.create_roi_analysis()\n","        shapley_chart = self.create_shapley_value_chart()\n","        network_graph = self.create_network_graph()\n","\n","        # è¡¨ç¤º\n","        skill_radar.show()\n","        synergy_heatmap.show()\n","        growth_trajectory.show()\n","        business_dashboard.show()\n","        monte_carlo_dist.show()\n","        roi_analysis.show()\n","        shapley_chart.show()\n","        network_graph.show()\n","\n","        print(\"âœ… å…¨ã¦ã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n","\n","        return {\n","            'skill_radar': skill_radar,\n","            'synergy_heatmap': synergy_heatmap,\n","            'growth_trajectory': growth_trajectory,\n","            'business_dashboard': business_dashboard,\n","            'monte_carlo_dist': monte_carlo_dist,\n","            'roi_analysis': roi_analysis,\n","            'shapley_chart': shapley_chart,\n","            'network_graph': network_graph\n","        }\n","\n","# å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ\n","viz_engine = VisualizationEngine(\n","    analysis_data, synergy_results, growth_solution, time_axis,\n","    business_forecast, shapley_values, nash_equilibrium,\n","    monte_carlo_results, roi_metrics\n",")\n","\n","all_charts = viz_engine.generate_all_visualizations()\n","\n","# ================================================================\n","# STEP 9: åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n","# ================================================================\n","\n","class ReportGenerator:\n","    def __init__(self, analysis_data, synergy_results, shapley_values,\n","                 nash_equilibrium, roi_metrics, monte_carlo_results,\n","                 compound_rates):\n","\n","        self.analysis_data = analysis_data\n","        self.synergy_results = synergy_results\n","        self.shapley_values = shapley_values\n","        self.nash_equilibrium = nash_equilibrium\n","        self.roi_metrics = roi_metrics\n","        self.monte_carlo_results = monte_carlo_results\n","        self.compound_rates = compound_rates\n","        self.names = list(analysis_data.keys())\n","\n","    def generate_executive_summary(self):\n","        \"\"\"ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ\"\"\"\n","\n","        # ä¸»è¦æŒ‡æ¨™è¨ˆç®—\n","        avg_synergy = np.mean(self.synergy_results['total_synergy'])\n","        max_synergy_pair = np.unravel_index(\n","            np.argmax(self.synergy_results['total_synergy']),\n","            self.synergy_results['total_synergy'].shape\n","        )\n","\n","        success_rate = self.monte_carlo_results['success_probability'].mean() * 100\n","        expected_roi = self.roi_metrics['final_roi_percent']\n","\n","        summary = f\"\"\"\n","# ğŸ¯ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼\n","\n","## ğŸ“ˆ ä¸»è¦åˆ†æçµæœ\n","\n","### ãƒãƒ¼ãƒ æ§‹æˆã®æˆ¦ç•¥çš„ä¾¡å€¤\n","- **ç·åˆã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢**: {avg_synergy:.3f} (1.0æº€ç‚¹)\n","- **æœ€å¼·ãƒšã‚¢**: {self.names[max_synergy_pair[0]]} Ã— {self.names[max_synergy_pair[1]]}\n","- **æˆåŠŸç¢ºç‡**: {success_rate:.1f}%\n","- **æœŸå¾…ROI**: {expected_roi:.1f}%\n","\n","### å€‹äººåˆ¥ä¾¡å€¤è²¢çŒ®åº¦ï¼ˆã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ï¼‰\n","\"\"\"\n","\n","        for i, name in enumerate(self.names):\n","            summary += f\"- **{name}**: {self.shapley_values[i]:.3f}\\n\"\n","\n","        summary += f\"\"\"\n","\n","### æˆé•·äºˆæ¸¬\n","- **{self.names[0]}**: {self.compound_rates[0]:.1f}% å¹´é–“æˆé•·ç‡\n","- **{self.names[1]}**: {self.compound_rates[1]:.1f}% å¹´é–“æˆé•·ç‡\n","- **{self.names[2]}**: {self.compound_rates[2]:.1f}% å¹´é–“æˆé•·ç‡\n","\n","### ğŸš€ æˆ¦ç•¥çš„æ¨å¥¨äº‹é …\n","1. **å³åº§ã«å®Ÿè¡Œ**: ç¾åœ¨ã®åˆ†æã§ã¯é«˜ã„ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœãŒæœŸå¾…ã§ãã‚‹\n","2. **Yasuyuki Sakaneã®å‚ç”»**: æ—¥æœ¬å¸‚å ´å±•é–‹ã®æˆ¦ç•¥çš„å„ªä½æ€§ã‚’æä¾›\n","3. **æŠ•è³‡å›åæœŸé–“**: ç´„{self.roi_metrics['payback_period_months']:.1f}ãƒ¶æœˆ\n","\n","### âš ï¸ é‡è¦ãªãƒªã‚¹ã‚¯è¦å› \n","- æ–‡åŒ–çš„é©å¿œæœŸé–“ï¼ˆ3-6ãƒ¶æœˆï¼‰\n","- æ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã®è¤‡é›‘åŒ–\n","- åˆæœŸæŠ•è³‡ã‚³ã‚¹ãƒˆã®å›åä¸ç¢ºå®Ÿæ€§\n","\n","---\n","\"\"\"\n","\n","        return summary\n","\n","    def generate_detailed_analysis(self):\n","        \"\"\"è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\"\"\"\n","\n","        detailed_report = \"\"\"\n","# ğŸ“Š è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n","\n","## 1. å€‹äººãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æ\n","\n","\"\"\"\n","\n","        for name in self.names:\n","            data = self.analysis_data[name]\n","            detailed_report += f\"\"\"\n","### {name}\n","- **çµŒé¨“å¹´æ•°**: {data['experience_years']}å¹´\n","- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦**: {data['network_strength']}/100\n","- **æ„Ÿæƒ…ã‚¹ã‚³ã‚¢**: {data['sentiment']:.3f}\n","- **ä¸»è¦ã‚¹ã‚­ãƒ«é ˜åŸŸ**: {max(data['skills'], key=data['skills'].get)}\n","\n","\"\"\"\n","\n","        detailed_report += \"\"\"\n","## 2. ã‚·ãƒŠã‚¸ãƒ¼åˆ†æãƒãƒˆãƒªãƒƒã‚¯ã‚¹\n","\n","### ã‚¹ã‚­ãƒ«è£œå®Œæ€§\n","\"\"\"\n","\n","        comp_matrix = self.synergy_results['skill_complementarity']\n","        for i in range(len(self.names)):\n","            for j in range(len(self.names)):\n","                if i != j:\n","                    detailed_report += f\"- {self.names[i]} â†’ {self.names[j]}: {comp_matrix[i,j]:.3f}\\n\"\n","\n","        detailed_report += \"\"\"\n","\n","## 3. è²¡å‹™çš„å½±éŸ¿åˆ†æ\n","\n","### ROIæŒ‡æ¨™\n","\"\"\"\n","\n","        detailed_report += f\"\"\"\n","- **æŠ•è³‡å›åæœŸé–“**: {self.roi_metrics['payback_period_months']:.1f}ãƒ¶æœˆ\n","- **æ­£å‘³ç¾åœ¨ä¾¡å€¤**: ${self.roi_metrics['npv']:,.0f}\n","- **æœ€çµ‚ROI**: {self.roi_metrics['final_roi_percent']:.1f}%\n","\n","### ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ\n","- **å¹³å‡æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: {self.monte_carlo_results['final_performance'].mean():.3f}\n","- **æ¨™æº–åå·®**: {self.monte_carlo_results['final_performance'].std():.3f}\n","- **95%ä¿¡é ¼åŒºé–“**: [{self.monte_carlo_results['final_performance'].quantile(0.025):.3f}, {self.monte_carlo_results['final_performance'].quantile(0.975):.3f}]\n","\n","## 4. ã‚²ãƒ¼ãƒ ç†è«–çš„åˆ†æ\n","\n","### ãƒŠãƒƒã‚·ãƒ¥å‡è¡¡æˆ¦ç•¥\n","\"\"\"\n","\n","        for i, name in enumerate(self.names):\n","            detailed_report += f\"- {name}: {self.nash_equilibrium[i]:.3f} (å”åŠ›ãƒ¬ãƒ™ãƒ«)\\n\"\n","\n","        detailed_report += \"\"\"\n","\n","## 5. å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n","\n","### Phase 1: æº–å‚™æœŸé–“ (0-3ãƒ¶æœˆ)\n","- ãƒãƒ¼ãƒ çµ±åˆãƒ—ãƒ­ã‚»ã‚¹è¨­è¨ˆ\n","- æ–‡åŒ–çš„é©å¿œæ”¯æ´\n","- åˆæœŸKPIè¨­å®š\n","\n","### Phase 2: ç«‹ã¡ä¸Šã’æœŸé–“ (3-6ãƒ¶æœˆ)\n","- æœ¬æ ¼çš„ãªå”æ¥­é–‹å§‹\n","- å®šæœŸçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š\n","- æ—©æœŸèª²é¡Œã®ç‰¹å®šã¨è§£æ±º\n","\n","### Phase 3: æˆé•·æœŸé–“ (6-12ãƒ¶æœˆ)\n","- ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœã®æœ€å¤§åŒ–\n","- æ–°è¦äº‹æ¥­æ©Ÿä¼šã®æ¢ç´¢\n","- é•·æœŸæˆ¦ç•¥ã®ç­–å®š\n","\n","### Phase 4: æ‹¡å¤§æœŸé–“ (12ãƒ¶æœˆä»¥é™)\n","- å¸‚å ´å±•é–‹ã®åŠ é€Ÿ\n","- çµ„ç¹”ã‚¹ã‚±ãƒ¼ãƒ«ã®æ‹¡å¤§\n","- ç¶™ç¶šçš„ãªæœ€é©åŒ–\n","\n","---\n","\"\"\"\n","\n","        return detailed_report\n","\n","    def generate_risk_assessment(self):\n","        \"\"\"ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ\"\"\"\n","\n","        risk_report = \"\"\"\n","# âš ï¸ ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ»ç·©å’Œæˆ¦ç•¥\n","\n","## é«˜ãƒªã‚¹ã‚¯è¦å› \n","\n","### 1. æ–‡åŒ–çš„é©å¿œãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 60%\n","- **å½±éŸ¿åº¦**: ä¸­ç¨‹åº¦\n","- **ç·©å’Œç­–**:\n","  - å®šæœŸçš„ãª1on1ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n","  - æ–‡åŒ–çš„èƒŒæ™¯ç†è§£ã®ãŸã‚ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—\n","  - ãƒ¡ãƒ³ã‚¿ãƒ¼åˆ¶åº¦ã®å°å…¥\n","\n","### 2. æ„æ€æ±ºå®šè¤‡é›‘åŒ–ãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 40%\n","- **å½±éŸ¿åº¦**: ä¸­ç¨‹åº¦\n","- **ç·©å’Œç­–**:\n","  - æ˜ç¢ºãªæ„æ€æ±ºå®šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ç­–å®š\n","  - å½¹å‰²åˆ†æ‹…ã®æ˜æ–‡åŒ–\n","  - ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã®è¨­è¨ˆ\n","\n","### 3. æŠ•è³‡å›åãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 25%\n","- **å½±éŸ¿åº¦**: é«˜\n","- **ç·©å’Œç­–**:\n","  - æ®µéšçš„æŠ•è³‡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n","  - ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³è¨­å®š\n","  - æ—©æœŸè­¦å‘ŠæŒ‡æ¨™ã®ç›£è¦–\n","\n","## ä¸­ãƒªã‚¹ã‚¯è¦å› \n","\n","### 1. ã‚¹ã‚­ãƒ«çµ±åˆãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 30%\n","- **å½±éŸ¿åº¦**: ä¸­ç¨‹åº¦\n","- **ç·©å’Œç­–**:\n","  - ã‚¹ã‚­ãƒ«è£œå®Œãƒãƒƒãƒ—ã®ä½œæˆ\n","  - å®šæœŸçš„ãªã‚¹ã‚­ãƒ«è©•ä¾¡\n","  - ç¶™ç¶šçš„ãªå­¦ç¿’æ©Ÿä¼šã®æä¾›\n","\n","### 2. å¸‚å ´ç’°å¢ƒå¤‰åŒ–ãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 35%\n","- **å½±éŸ¿åº¦**: ä¸­ç¨‹åº¦\n","- **ç·©å’Œç­–**:\n","  - å¸‚å ´å‹•å‘ã®ç¶™ç¶šçš„ç›£è¦–\n","  - æŸ”è»Ÿãªæˆ¦ç•¥èª¿æ•´èƒ½åŠ›\n","  - è¤‡æ•°å¸‚å ´ã¸ã®åˆ†æ•£æŠ•è³‡\n","\n","## ä½ãƒªã‚¹ã‚¯è¦å› \n","\n","### 1. æŠ€è¡“çš„ãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 15%\n","- **å½±éŸ¿åº¦**: ä½\n","- **ç·©å’Œç­–**: æ—¢å­˜ã®æŠ€è¡“å°‚é–€æ€§ã‚’æ´»ç”¨\n","\n","### 2. æ³•çš„ãƒ»è¦åˆ¶ãƒªã‚¹ã‚¯\n","- **ç¢ºç‡**: 10%\n","- **å½±éŸ¿åº¦**: ä½\n","- **ç·©å’Œç­–**: å°‚é–€å®¶ã«ã‚ˆã‚‹ç¶™ç¶šçš„ãªã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç›£è¦–\n","\n","---\n","\"\"\"\n","\n","        return risk_report\n","\n","    def export_full_report(self):\n","        \"\"\"å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›\"\"\"\n","\n","        full_report = self.generate_executive_summary()\n","        full_report += self.generate_detailed_analysis()\n","        full_report += self.generate_risk_assessment()\n","\n","        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        filename = f\"/content/drive/MyDrive/synergy_analysis_report_{timestamp}.md\"\n","\n","        try:\n","            with open(filename, 'w', encoding='utf-8') as f:\n","                f.write(full_report)\n","            print(f\"âœ… ãƒ¬ãƒãƒ¼ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {filename}\")\n","        except Exception as e:\n","            print(f\"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n","\n","        return full_report\n","\n","# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Ÿè¡Œ\n","report_generator = ReportGenerator(\n","    analysis_data, synergy_results, shapley_values, nash_equilibrium,\n","    roi_metrics, monte_carlo_results, compound_rates\n",")\n","\n","final_report = report_generator.export_full_report()\n","\n","# ================================================================\n","# STEP 10: çµæœè¡¨ç¤ºã¨ã‚µãƒãƒªãƒ¼\n","# ================================================================\n","\n","print(\"=\"*80)\n","print(\"ğŸ‰ äººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n","print(\"=\"*80)\n","\n","# ä¸»è¦çµæœã®è¡¨ç¤º\n","print(\"\\nğŸ“Š ä¸»è¦åˆ†æçµæœ:\")\n","print(f\"â€¢ å¹³å‡ã‚·ãƒŠã‚¸ãƒ¼ã‚¹ã‚³ã‚¢: {np.mean(synergy_results['total_synergy']):.3f}\")\n","print(f\"â€¢ æœŸå¾…ROI: {roi_metrics['final_roi_percent']:.1f}%\")\n","print(f\"â€¢ æˆåŠŸç¢ºç‡: {monte_carlo_results['success_probability'].mean()*100:.1f}%\")\n","\n","print(\"\\nğŸ‘¥ å€‹äººåˆ¥ä¾¡å€¤è²¢çŒ®åº¦:\")\n","for i, name in enumerate(list(analysis_data.keys())):\n","    print(f\"â€¢ {name}: {shapley_values[i]:.3f}\")\n","\n","print(\"\\nğŸ“ˆ å¹´é–“æˆé•·ç‡äºˆæ¸¬:\")\n","for i, name in enumerate(list(analysis_data.keys())):\n","    print(f\"â€¢ {name}: {compound_rates[i]:.1f}%\")\n","\n","print(\"\\nğŸ¯ æˆ¦ç•¥çš„æ¨å¥¨äº‹é …:\")\n","print(\"1. Yasuyuki Sakaneã®å‚ç”»ã‚’å¼·ãæ¨å¥¨\")\n","print(\"2. åˆæœŸ6ãƒ¶æœˆé–“ã®æ–‡åŒ–é©å¿œæœŸé–“ã‚’è¨­å®š\")\n","print(\"3. å®šæœŸçš„ãªã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœæ¸¬å®šã‚’å®Ÿæ–½\")\n","\n","print(\"\\nğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆ:\")\n","print(\"â€¢ 8ã¤ã®å¯è¦–åŒ–ãƒãƒ£ãƒ¼ãƒˆ\")\n","print(\"â€¢ åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\")\n","print(\"â€¢ ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ»ç·©å’Œç­–\")\n","print(\"â€¢ ROIãƒ»è²¡å‹™åˆ†æ\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"ğŸš€ åˆ†æå®Œäº†ï¼Googleãƒ‰ãƒ©ã‚¤ãƒ–ã«ãƒ¬ãƒãƒ¼ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚\")\n","print(\"=\"*80)\n","\n","# ================================================================\n","# STEP 11: è¿½åŠ ã®åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³\n","# ================================================================\n","\n","def run_sensitivity_analysis():\n","    \"\"\"æ„Ÿåº¦åˆ†æå®Ÿè¡Œ\"\"\"\n","    print(\"\\nğŸ” æ„Ÿåº¦åˆ†æã‚’å®Ÿè¡Œä¸­...\")\n","\n","    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰å‹•ã«ã‚ˆã‚‹å½±éŸ¿ã‚’åˆ†æ\n","    base_synergy = np.mean(synergy_results['total_synergy'])\n","\n","    # å„è¦ç´ ã®é‡è¦åº¦ã‚’æ¸¬å®š\n","    sensitivity_results = {}\n","\n","    # ã‚¹ã‚­ãƒ«é‡ã¿ã®å¤‰å‹•\n","    for weight_change in [-0.1, -0.05, 0.05, 0.1]:\n","        modified_synergy = base_synergy * (1 + weight_change)\n","        sensitivity_results[f'skill_weight_{weight_change:+.2f}'] = modified_synergy\n","\n","    print(\"âœ… æ„Ÿåº¦åˆ†æå®Œäº†\")\n","    return sensitivity_results\n","\n","def run_what_if_scenarios():\n","    \"\"\"What-if ã‚·ãƒŠãƒªã‚ªåˆ†æ\"\"\"\n","    print(\"\\nğŸ”® What-ifã‚·ãƒŠãƒªã‚ªåˆ†æã‚’å®Ÿè¡Œä¸­...\")\n","\n","    scenarios = {\n","        'best_case': {'market_factor': 1.2, 'synergy_factor': 1.3},\n","        'worst_case': {'market_factor': 0.8, 'synergy_factor': 0.7},\n","        'realistic': {'market_factor': 1.0, 'synergy_factor': 1.0}\n","    }\n","\n","    scenario_results = {}\n","\n","    for scenario_name, factors in scenarios.items():\n","        adjusted_roi = roi_metrics['final_roi_percent'] * factors['market_factor'] * factors['synergy_factor']\n","        scenario_results[scenario_name] = adjusted_roi\n","        print(f\"â€¢ {scenario_name}: {adjusted_roi:.1f}% ROI\")\n","\n","    print(\"âœ… What-ifã‚·ãƒŠãƒªã‚ªåˆ†æå®Œäº†\")\n","    return scenario_results\n","\n","# è¿½åŠ åˆ†æã®å®Ÿè¡Œ\n","sensitivity_results = run_sensitivity_analysis()\n","scenario_results = run_what_if_scenarios()\n","\n","print(\"\\nğŸŠ å…¨ã¦ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n","print(\"ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’Google Colabã§å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€åŒ…æ‹¬çš„ãªäººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚\")\n","print(\"å¿…è¦ã«å¿œã˜ã¦ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„åˆ†ææ‰‹æ³•ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚\")\n","\n","# ===============================================================\n","# STEP 12: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚°ãƒ©ãƒ•ã‚’HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n","# ===============================================================\n","\n","import os\n","\n","# ä¿å­˜å…ˆã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®š\n","save_path = \"/content/drive/MyDrive/synergy_analysis_charts/\"\n","\n","# ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","    print(f\"âœ… ä¿å­˜ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {save_path}\")\n","\n","# all_chartsãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªå†…ã®å„ã‚°ãƒ©ãƒ•ã‚’HTMLã¨ã—ã¦ä¿å­˜\n","for chart_name, chart_figure in all_charts.items():\n","    file_path = f\"{save_path}{chart_name}.html\"\n","    try:\n","        chart_figure.write_html(file_path)\n","        print(f\"âœ… ã‚°ãƒ©ãƒ• '{chart_name}' ã‚’HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã—ãŸ: {file_path}\")\n","    except Exception as e:\n","        print(f\"âš ï¸ '{chart_name}' ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM8vAr0FTIs6Lmj9mfqhilM","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
