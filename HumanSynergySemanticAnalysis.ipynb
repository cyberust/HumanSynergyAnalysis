{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe3KM4S1cSQYB3agJs/qVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyberust/HumanSynergyAnalysis/blob/main/HumanSynergySemanticAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKO4chrp6Qlc",
        "outputId": "d761d07d-d7fc-44c2-8339-e159d74acbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "#\n",
        "#  äººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ  V2 - ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æç‰ˆ\n",
        "#\n",
        "#  V1ã‹ã‚‰ã®æ”¹å–„ç‚¹:\n",
        "#  - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®åˆ†æã‚’å»ƒæ­¢\n",
        "#  - sentence-transformers ã‚’ç”¨ã„ãŸæ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆEmbeddingï¼‰ã«ã‚ˆã‚‹åˆ†æã‚’å°å…¥\n",
        "#  - ã‚ˆã‚Šç²¾ç·»ã§ä¿¡é ¼æ€§ã®é«˜ã„ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—ã¨ä¾¡å€¤è²¢çŒ®åº¦åˆ†æã‚’å®Ÿç¾\n",
        "#\n",
        "# ======================================================================\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 1: å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®š\n",
        "# ===============================================================\n",
        "\n",
        "# V2ã§æ–°ãŸã«è¿½åŠ ï¼šæ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "!pip install sentence-transformers --quiet\n",
        "\n",
        "# V1ã‹ã‚‰ç¶™ç¶šã—ã¦ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "!pip install networkx matplotlib seaborn plotly kaleido --quiet\n",
        "!pip install scikit-learn pandas numpy scipy --quiet\n",
        "\n",
        "# Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ•°å­¦ãƒ»çµ±è¨ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "from scipy.integrate import odeint\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# NLPï¼ˆè‡ªç„¶è¨€èªå‡¦ç†ï¼‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ãã®ä»–\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"âœ… V2: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 2: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ï¼ˆV1ã‹ã‚‰å¤‰æ›´ãªã—ï¼‰\n",
        "# ===============================================================\n",
        "\n",
        "def load_profile_data():\n",
        "    \"\"\"Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€\"\"\"\n",
        "    base_path = \"/content/drive/MyDrive/\"\n",
        "    profiles = {}\n",
        "    names = [\"arale_cohen\", \"yanay_geva\", \"yasuyuki_sakane\"]\n",
        "    display_names = [\"Arale Cohen\", \"Yanay Geva\", \"Yasuyuki Sakane\"]\n",
        "\n",
        "    for name, display_name in zip(names, display_names):\n",
        "        try:\n",
        "            with open(f\"{base_path}{name}_profile.txt\", 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "            profiles[display_name] = content\n",
        "            print(f\"âœ… {display_name}ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"âš ï¸ {name}_profile.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "            profiles[display_name] = \"Profile data not available.\"\n",
        "    return profiles\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Ÿè¡Œ\n",
        "profiles = load_profile_data()\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 3: ã€V2ã®æ ¸å¿ƒã€‘ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æ\n",
        "# ===============================================================\n",
        "\n",
        "class SemanticProfileAnalyzer:\n",
        "    def __init__(self):\n",
        "        # äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "        # 'all-MiniLM-L6-v2' ã¯é«˜é€Ÿã‹ã¤é«˜å“è³ªãªè‹±èªãƒ¢ãƒ‡ãƒ«\n",
        "        print(\"ğŸ¤– è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        print(\"âœ… è¨€èªãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "    def analyze_all_profiles(self, profiles_dict):\n",
        "        \"\"\"ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã€ä»–ã®ç‰¹å¾´ã‚‚æŠ½å‡ºã™ã‚‹\"\"\"\n",
        "        analysis_results = {}\n",
        "        profile_names = list(profiles_dict.keys())\n",
        "        profile_texts = list(profiles_dict.values())\n",
        "\n",
        "        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å…¨ä½“ã‚’æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã«ä¸€æ‹¬å¤‰æ›\n",
        "        print(\"ğŸ§  å…¨å“¡ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ä¸­...\")\n",
        "        embeddings = self.model.encode(profile_texts, show_progress_bar=True)\n",
        "        print(\"âœ… ãƒ™ã‚¯ãƒˆãƒ«å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "        for i, name in enumerate(profile_names):\n",
        "            # çµŒé¨“å¹´æ•°ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦ã¯V1ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ‰‹æ³•ã‚’æµç”¨\n",
        "            # NOTE: ã“ã‚Œã‚‰ã®æŠ½å‡ºæ–¹æ³•ã‚‚ã€å°†æ¥çš„ã«ã¯ã‚ˆã‚Šé«˜åº¦åŒ–ã§ãã‚‹\n",
        "            experience = self._extract_experience_years(profile_texts[i])\n",
        "            network = self._extract_network_strength(profile_texts[i])\n",
        "\n",
        "            analysis_results[name] = {\n",
        "                'embedding': embeddings[i], # æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«\n",
        "                'experience_years': experience,\n",
        "                'network_strength': network,\n",
        "                'raw_profile': profile_texts[i]\n",
        "            }\n",
        "        return analysis_results\n",
        "\n",
        "    def _extract_experience_years(self, text):\n",
        "        \"\"\"çµŒé¨“å¹´æ•°ã‚’æŠ½å‡º\"\"\"\n",
        "        matches = re.findall(r'(\\d+)\\+?\\s*years?', text.lower())\n",
        "        return max([int(match) for match in matches]) if matches else 10\n",
        "\n",
        "    def _extract_network_strength(self, text):\n",
        "        \"\"\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¼·åº¦ã‚’æ¨å®š\"\"\"\n",
        "        indicators = ['network', 'ecosystem', 'connections', 'board member', 'partner']\n",
        "        score = sum(text.lower().count(indicator) for indicator in indicators)\n",
        "        return min(score * 20, 100)\n",
        "\n",
        "# ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æå®Ÿè¡Œ\n",
        "analyzer = SemanticProfileAnalyzer()\n",
        "analysis_data = analyzer.analyze_all_profiles(profiles)\n",
        "\n",
        "print(\"âœ… V2: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 4: ã€V2ã®æ ¸å¿ƒã€‘ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—\n",
        "# ===============================================================\n",
        "\n",
        "class SemanticSynergyCalculator:\n",
        "    def __init__(self, analysis_data):\n",
        "        self.data = analysis_data\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def calculate_skill_complementarity(self):\n",
        "        \"\"\"æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ç”¨ã„ã¦ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã‚’è¨ˆç®—\"\"\"\n",
        "        # å…¨å“¡ã®æ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã‚¹ã‚¿ãƒƒã‚¯\n",
        "        embeddings = np.array([self.data[name]['embedding'] for name in self.names])\n",
        "\n",
        "        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®— (å€¤ãŒé«˜ã„ã»ã©ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆãŒè¿‘ã„)\n",
        "        similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "        # è£œå®Œæ€§ã¯ (1 - é¡ä¼¼åº¦) ã§å®šç¾©\n",
        "        complementarity_matrix = 1 - similarity_matrix\n",
        "        return complementarity_matrix\n",
        "\n",
        "    def calculate_total_synergy_matrix(self):\n",
        "        \"\"\"ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—\"\"\"\n",
        "        # V2: ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã®è¨ˆç®—æ–¹æ³•ãŒæ–°ã—ããªã£ãŸ\n",
        "        comp_matrix = self.calculate_skill_complementarity()\n",
        "\n",
        "        # V1ã‹ã‚‰æµç”¨ã™ã‚‹è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯\n",
        "        experiences = [self.data[name]['experience_years'] for name in self.names]\n",
        "        networks = [self.data[name]['network_strength'] for name in self.names]\n",
        "        exp_matrix = self._calculate_experience_synergy(experiences)\n",
        "        net_matrix = self._calculate_network_effects(networks)\n",
        "        div_matrix = self._calculate_cultural_diversity_bonus()\n",
        "\n",
        "        # é‡ã¿ä»˜ãçµ±åˆï¼ˆèª¿æ•´å¯èƒ½ï¼‰\n",
        "        weights = {\n",
        "            'complementarity': 0.4, # ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã®é‡è¦åº¦ã‚’ä¸Šã’ã‚‹\n",
        "            'experience': 0.2,\n",
        "            'network': 0.2,\n",
        "            'diversity': 0.2\n",
        "        }\n",
        "\n",
        "        total_synergy = (\n",
        "            weights['complementarity'] * comp_matrix +\n",
        "            weights['experience'] * exp_matrix +\n",
        "            weights['network'] * net_matrix\n",
        "        ) * div_matrix # å¤šæ§˜æ€§ãƒœãƒ¼ãƒŠã‚¹ã¯ä¹—ç®—ã§é©ç”¨\n",
        "\n",
        "        # è‡ªåˆ†è‡ªèº«ã¨ã®ã‚·ãƒŠã‚¸ãƒ¼ã¯0ã«ã™ã‚‹\n",
        "        np.fill_diagonal(total_synergy, 0)\n",
        "\n",
        "        return {\n",
        "            'total_synergy': total_synergy,\n",
        "            'skill_complementarity': comp_matrix\n",
        "        }\n",
        "\n",
        "    # ä»¥ä¸‹ã¯V1ã‹ã‚‰æµç”¨ã™ã‚‹ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰\n",
        "    def _calculate_experience_synergy(self, experiences):\n",
        "        synergy_matrix = np.zeros((3, 3))\n",
        "        for i, j in np.ndindex(synergy_matrix.shape):\n",
        "            if i != j:\n",
        "                exp_diff = abs(experiences[i] - experiences[j])\n",
        "                synergy_matrix[i, j] = np.exp(-0.1 * exp_diff) # å·®ãŒå°ã•ã„ã»ã©é«˜ã„\n",
        "        return synergy_matrix\n",
        "\n",
        "    def _calculate_network_effects(self, networks):\n",
        "        network_matrix = np.zeros((3, 3))\n",
        "        for i, j in np.ndindex(network_matrix.shape):\n",
        "            if i != j:\n",
        "                network_matrix[i, j] = (networks[i] * networks[j]) / 10000.0\n",
        "        return network_matrix\n",
        "\n",
        "    def _calculate_cultural_diversity_bonus(self):\n",
        "        backgrounds = {'Arale Cohen': 'Western', 'Yanay Geva': 'Western', 'Yasuyuki Sakane': 'Eastern'}\n",
        "        diversity_matrix = np.ones((3, 3))\n",
        "        for i, name1 in enumerate(self.names):\n",
        "            for j, name2 in enumerate(self.names):\n",
        "                if backgrounds[name1] != backgrounds[name2]:\n",
        "                    diversity_matrix[i, j] = 1.2 # ç•°ãªã‚‹æ–‡åŒ–èƒŒæ™¯ã«20%ã®ãƒœãƒ¼ãƒŠã‚¹\n",
        "        return diversity_matrix\n",
        "\n",
        "# ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—å®Ÿè¡Œ\n",
        "synergy_calc = SemanticSynergyCalculator(analysis_data)\n",
        "synergy_results = synergy_calc.calculate_total_synergy_matrix()\n",
        "\n",
        "print(\"âœ… V2: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚·ãƒŠã‚¸ãƒ¼è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 5: å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆå®‰å®šç‰ˆã‚’æ¨™æº–æ­è¼‰ï¼‰\n",
        "# ===============================================================\n",
        "\n",
        "# ä»¥å‰ã®å¯¾è©±ã§å®‰å®šåŒ–ã—ãŸæœ€çµ‚ç‰ˆã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ä½¿ç”¨\n",
        "class DynamicSystemModel:\n",
        "    def __init__(self, synergy_results, analysis_data):\n",
        "        self.synergy_matrix = synergy_results['total_synergy']\n",
        "        self.data = analysis_data\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def define_system_parameters(self):\n",
        "        \"\"\"ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ï¼ˆå®‰å®šæ€§ã‚’æœ€å„ªå…ˆã—ãŸãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯æˆé•·ãƒ¢ãƒ‡ãƒ«ï¼‰\"\"\"\n",
        "        alpha = np.array([0.4, 0.35, 0.45]) # å€‹äººã®åŸºç¤æˆé•·ç‡\n",
        "        beta = self.synergy_matrix * 0.1 # ã‚·ãƒŠã‚¸ãƒ¼åŠ¹æœ\n",
        "        K = np.array([12.0, 12.0, 12.0]) # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸Šé™\n",
        "        return alpha, beta, K\n",
        "\n",
        "    def system_dynamics(self, state, t, alpha, beta, K):\n",
        "        \"\"\"å‹•çš„ã‚·ã‚¹ãƒ†ãƒ æ–¹ç¨‹å¼ï¼ˆçµåˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯æˆé•·ãƒ¢ãƒ‡ãƒ«ï¼‰\"\"\"\n",
        "        x1, x2, x3 = state\n",
        "        dx1dt = (alpha[0] * x1 + beta[0,1] * x2 + beta[0,2] * x3) * (1 - x1 / K[0])\n",
        "        dx2dt = (alpha[1] * x2 + beta[1,0] * x1 + beta[1,2] * x3) * (1 - x2 / K[1])\n",
        "        dx3dt = (alpha[2] * x3 + beta[2,0] * x1 + beta[2,1] * x2) * (1 - x3 / K[2])\n",
        "        return [dx1dt, dx2dt, dx3dt]\n",
        "\n",
        "    def simulate_growth(self, initial_state=None, time_horizon=24):\n",
        "        \"\"\"æˆé•·ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ\"\"\"\n",
        "        if initial_state is None:\n",
        "            initial_state = [1.0, 1.0, 1.0] # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’1.0ã«è¨­å®š\n",
        "        alpha, beta, K = self.define_system_parameters()\n",
        "        t = np.linspace(0, time_horizon, time_horizon * 4)\n",
        "        solution = odeint(self.system_dynamics, initial_state, t, args=(alpha, beta, K))\n",
        "        return t, solution, (alpha, beta, K)\n",
        "\n",
        "# å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ\n",
        "dynamic_model = DynamicSystemModel(synergy_results, analysis_data)\n",
        "time_axis, growth_solution, _ = dynamic_model.simulate_growth()\n",
        "\n",
        "print(\"âœ… V2: å‹•çš„ã‚·ã‚¹ãƒ†ãƒ ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 6: ã‚²ãƒ¼ãƒ ç†è«–åˆ†æï¼ˆã‚ˆã‚Šæ„å‘³ã®ã‚ã‚‹å…¥åŠ›ã§å®Ÿè¡Œï¼‰\n",
        "# ===============================================================\n",
        "# V2ã®ç²¾ç·»åŒ–ã•ã‚ŒãŸã‚·ãƒŠã‚¸ãƒ¼å€¤ã‚’å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã€\n",
        "# ã‚²ãƒ¼ãƒ ç†è«–åˆ†æã®çµæœã‚‚ã€ã‚ˆã‚Šç¾å®Ÿçš„ãªã‚‚ã®ã«ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹\n",
        "\n",
        "class GameTheoryAnalysis:\n",
        "    def __init__(self, synergy_results, analysis_data):\n",
        "        self.synergy_matrix = synergy_results['total_synergy']\n",
        "        self.data = analysis_data\n",
        "        self.names = list(analysis_data.keys())\n",
        "        self.n_players = len(self.names)\n",
        "\n",
        "    def _get_coalition_value(self, coalition_indices):\n",
        "        \"\"\"é€£åˆã®ä¾¡å€¤ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\"\"\"\n",
        "        if not coalition_indices:\n",
        "            return 0\n",
        "\n",
        "        # é€£åˆå†…ã®å€‹äººã®åŸºç¤ä¾¡å€¤ã®åˆè¨ˆ\n",
        "        base_value = sum((self.data[self.names[i]]['experience_years'] +\n",
        "                          self.data[self.names[i]]['network_strength'] / 10.0)\n",
        "                         for i in coalition_indices)\n",
        "\n",
        "        # é€£åˆå†…ã®ã‚·ãƒŠã‚¸ãƒ¼ã®åˆè¨ˆ\n",
        "        synergy_value = 0\n",
        "        if len(coalition_indices) > 1:\n",
        "            for i in coalition_indices:\n",
        "                for j in coalition_indices:\n",
        "                    synergy_value += self.synergy_matrix[i, j]\n",
        "\n",
        "        # åŸºç¤ä¾¡å€¤ã¨ã‚·ãƒŠã‚¸ãƒ¼ä¾¡å€¤ã‚’çµ±åˆ\n",
        "        return base_value + synergy_value * 5 # ã‚·ãƒŠã‚¸ãƒ¼ã®ä¾¡å€¤ã‚’å¼·èª¿\n",
        "\n",
        "    def calculate_shapley_values(self):\n",
        "        \"\"\"ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã‚’è¨ˆç®—\"\"\"\n",
        "        from math import factorial\n",
        "        from itertools import combinations\n",
        "\n",
        "        shapley_values = np.zeros(self.n_players)\n",
        "        all_players_set = set(range(self.n_players))\n",
        "\n",
        "        for i in range(self.n_players):\n",
        "            for coalition_size in range(self.n_players):\n",
        "                num_combinations = 0\n",
        "                total_marginal_contribution = 0\n",
        "\n",
        "                other_players = list(all_players_set - {i})\n",
        "                for coalition in combinations(other_players, coalition_size):\n",
        "                    coalition_with_i = list(coalition) + [i]\n",
        "                    coalition_without_i = list(coalition)\n",
        "\n",
        "                    marginal_contribution = self._get_coalition_value(coalition_with_i) - self._get_coalition_value(coalition_without_i)\n",
        "                    shapley_values[i] += marginal_contribution\n",
        "\n",
        "        # æ­£è¦åŒ–\n",
        "        total_value_all_players = self._get_coalition_value(list(all_players_set))\n",
        "        current_total_shapley = np.sum(shapley_values)\n",
        "        if current_total_shapley > 0:\n",
        "            shapley_values = (shapley_values / current_total_shapley) * total_value_all_players\n",
        "\n",
        "        return shapley_values\n",
        "\n",
        "# ã‚²ãƒ¼ãƒ ç†è«–åˆ†æå®Ÿè¡Œ\n",
        "game_analysis = GameTheoryAnalysis(synergy_results, analysis_data)\n",
        "shapley_values = game_analysis.calculate_shapley_values()\n",
        "\n",
        "print(\"âœ… V2: ã‚²ãƒ¼ãƒ ç†è«–åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 7: äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆå®‰å®šã—ãŸå…¥åŠ›ã§å®Ÿè¡Œï¼‰\n",
        "# ===============================================================\n",
        "\n",
        "class PredictionModel:\n",
        "    def __init__(self, growth_solution, time_axis, synergy_results):\n",
        "        self.growth_data = growth_solution\n",
        "        self.time_axis = time_axis\n",
        "        self.synergy_matrix = synergy_results['total_synergy']\n",
        "\n",
        "    def forecast_business_metrics(self):\n",
        "        \"\"\"ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™äºˆæ¸¬\"\"\"\n",
        "        performance_data = []\n",
        "        for t in range(len(self.time_axis)):\n",
        "            individual_performance = self.growth_data[t]\n",
        "            # team_synergy ã®è¨ˆç®—å¼ã‚’ã‚ˆã‚Šå®‰å®šãªã‚‚ã®ã«\n",
        "            team_synergy = np.sum(self.synergy_matrix * np.outer(individual_performance, individual_performance)) / 2\n",
        "\n",
        "            # å„æŒ‡æ¨™ã®è¨ˆç®—\n",
        "            revenue_growth = np.sum(individual_performance) * 10 + team_synergy * 5\n",
        "            innovation_index = team_synergy * 10\n",
        "            market_share = min(np.sum(individual_performance) + team_synergy, 40)\n",
        "            customer_satisfaction = min(75 + team_synergy, 98)\n",
        "\n",
        "            performance_data.append({\n",
        "                'time_months': self.time_axis[t],\n",
        "                'revenue_growth_rate': revenue_growth,\n",
        "                'innovation_index': innovation_index,\n",
        "                'market_share_percent': market_share,\n",
        "                'customer_satisfaction': customer_satisfaction\n",
        "            })\n",
        "        return pd.DataFrame(performance_data)\n",
        "\n",
        "# äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å®Ÿè¡Œ\n",
        "prediction_model = PredictionModel(growth_solution, time_axis, synergy_results)\n",
        "business_forecast = prediction_model.forecast_business_metrics()\n",
        "\n",
        "print(\"âœ… V2: äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 8: å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆV1ã‹ã‚‰ã‚³ãƒ¼ãƒ‰æµç”¨ã€æç”»å†…å®¹ãŒå¤‰åŒ–ï¼‰\n",
        "# ===============================================================\n",
        "\n",
        "# V1ã®VisualizationEngineã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒå¤‰ã‚ã‚‹ã“ã¨ã§\n",
        "# V2ã®åˆ†æçµæœã‚’å¯è¦–åŒ–ã™ã‚‹å½¹å‰²ã‚’æ‹…ã†\n",
        "class VisualizationEngine:\n",
        "    def __init__(self, analysis_data, synergy_results, growth_solution,\n",
        "                 time_axis, business_forecast, shapley_values):\n",
        "        self.analysis_data = analysis_data\n",
        "        self.synergy_results = synergy_results\n",
        "        self.growth_solution = growth_solution\n",
        "        self.time_axis = time_axis\n",
        "        self.business_forecast = business_forecast\n",
        "        self.shapley_values = shapley_values\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def create_synergy_heatmap(self):\n",
        "        \"\"\"ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\"\"\"\n",
        "        synergy_matrix = self.synergy_results['total_synergy']\n",
        "        fig = px.imshow(synergy_matrix,\n",
        "                        labels=dict(x=\"ãƒ¡ãƒ³ãƒãƒ¼\", y=\"ãƒ¡ãƒ³ãƒãƒ¼\", color=\"ã‚·ãƒŠã‚¸ãƒ¼å¼·åº¦\"),\n",
        "                        x=self.names, y=self.names,\n",
        "                        text_auto='.3f',\n",
        "                        color_continuous_scale='Blues')\n",
        "        fig.update_layout(title_text='V2: ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ç‰ˆï¼‰')\n",
        "        return fig\n",
        "\n",
        "    def create_growth_trajectory(self):\n",
        "        \"\"\"å‹•çš„æˆé•·è»Œé“\"\"\"\n",
        "        df = pd.DataFrame(self.growth_solution, columns=self.names)\n",
        "        df['Time'] = self.time_axis\n",
        "        fig = px.line(df, x='Time', y=self.names,\n",
        "                      labels={'value': 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ•°', 'Time': 'æ™‚é–“ï¼ˆæœˆï¼‰'},\n",
        "                      title='V2: å‹•çš„æˆé•·è»Œé“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®‰å®šç‰ˆï¼‰')\n",
        "        return fig\n",
        "\n",
        "    def create_business_metrics_dashboard(self):\n",
        "        \"\"\"ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰\"\"\"\n",
        "        df = self.business_forecast\n",
        "        fig = make_subplots(rows=2, cols=2, subplot_titles=('å£²ä¸Šæˆé•·ç‡', 'ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°', 'ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢', 'é¡§å®¢æº€è¶³åº¦'))\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['revenue_growth_rate'], name='å£²ä¸Šæˆé•·ç‡'), row=1, col=1)\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['innovation_index'], name='ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æŒ‡æ•°'), row=1, col=2)\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['market_share_percent'], name='ãƒãƒ¼ã‚±ãƒƒãƒˆã‚·ã‚§ã‚¢'), row=2, col=1)\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['customer_satisfaction'], name='é¡§å®¢æº€è¶³åº¦'), row=2, col=2)\n",
        "        fig.update_layout(title_text='V2: ãƒ“ã‚¸ãƒã‚¹æŒ‡æ¨™äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰', showlegend=False)\n",
        "        return fig\n",
        "\n",
        "    def create_shapley_value_chart(self):\n",
        "        \"\"\"ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã«ã‚ˆã‚‹ä¾¡å€¤è²¢çŒ®åº¦\"\"\"\n",
        "        fig = px.bar(x=self.names, y=self.shapley_values,\n",
        "                     labels={'x': 'ãƒ¡ãƒ³ãƒãƒ¼', 'y': 'ä¾¡å€¤è²¢çŒ®åº¦ï¼ˆã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ï¼‰'},\n",
        "                     text=np.round(self.shapley_values, 2),\n",
        "                     title='V2: ã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ã«ã‚ˆã‚‹ä¾¡å€¤è²¢çŒ®åº¦åˆ†æ')\n",
        "        return fig\n",
        "\n",
        "    def create_network_graph(self):\n",
        "        \"\"\"V1ã®ãƒã‚°ã‚’ä¿®æ­£ã—ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•\"\"\"\n",
        "        G = nx.Graph()\n",
        "        for i, name in enumerate(self.names):\n",
        "            G.add_node(name, size=self.analysis_data[name]['network_strength'])\n",
        "\n",
        "        synergy_matrix = self.synergy_results['total_synergy']\n",
        "        for i, j in np.ndindex(synergy_matrix.shape):\n",
        "            if i < j:\n",
        "                G.add_edge(self.names[i], self.names[j], weight=synergy_matrix[i, j])\n",
        "\n",
        "        pos = nx.spring_layout(G, k=1.5, iterations=50)\n",
        "\n",
        "        edge_traces = []\n",
        "        for edge in G.edges(data=True):\n",
        "            x0, y0 = pos[edge[0]]\n",
        "            x1, y1 = pos[edge[1]]\n",
        "            w = edge[2]['weight'] * 15\n",
        "            edge_traces.append(go.Scatter(x=[x0, x1, None], y=[y0, y1, None], mode='lines',\n",
        "                                        line=dict(width=w, color='rgba(150,150,150,0.5)'),\n",
        "                                        hoverinfo='text', text=f\"Synergy: {w/15:.3f}\"))\n",
        "\n",
        "        node_trace = go.Scatter(x=[pos[n][0] for n in G.nodes()],\n",
        "                                y=[pos[n][1] for n in G.nodes()],\n",
        "                                mode='markers+text',\n",
        "                                text=self.names, textposition=\"top center\",\n",
        "                                marker=dict(size=[d['size']/5 for n, d in G.nodes(data=True)],\n",
        "                                            color=['#FF6B6B', '#4ECDC4', '#45B7D1']),\n",
        "                                hoverinfo='none')\n",
        "\n",
        "        fig = go.Figure(data=edge_traces + [node_trace],\n",
        "                        layout=go.Layout(title='V2: ãƒãƒ¼ãƒ ç›¸äº’ä½œç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', showlegend=False,\n",
        "                                         xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                                         yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
        "        return fig\n",
        "\n",
        "    def generate_all_visualizations(self):\n",
        "        \"\"\"å…¨ã¦ã®å¯è¦–åŒ–ã‚’ç”Ÿæˆãƒ»è¡¨ç¤º\"\"\"\n",
        "        print(\"\\nğŸ“Š V2: å¯è¦–åŒ–ã‚’ç”Ÿæˆä¸­...\")\n",
        "\n",
        "        # V2ã§æ„å‘³ã‚’æŒã¤ã‚ˆã†ã«ãªã£ãŸã‚°ãƒ©ãƒ•ã‚’ä¸­å¿ƒã«å¯è¦–åŒ–\n",
        "        self.create_synergy_heatmap().show()\n",
        "        self.create_growth_trajectory().show()\n",
        "        self.create_business_metrics_dashboard().show()\n",
        "        self.create_shapley_value_chart().show()\n",
        "        self.create_network_graph().show()\n",
        "\n",
        "        print(\"âœ… V2: å…¨ã¦ã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "\n",
        "# å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œ\n",
        "viz_engine = VisualizationEngine(analysis_data, synergy_results, growth_solution,\n",
        "                                 time_axis, business_forecast, shapley_values)\n",
        "viz_engine.generate_all_visualizations()\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 9: åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n",
        "# ===============================================================\n",
        "# V2ã®åˆ†æçµæœã«åŸºã¥ã„ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ\n",
        "\n",
        "class ReportGenerator:\n",
        "    def __init__(self, analysis_data, synergy_results, shapley_values):\n",
        "        self.analysis_data = analysis_data\n",
        "        self.synergy_results = synergy_results\n",
        "        self.shapley_values = shapley_values\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def generate_report(self):\n",
        "        \"\"\"åˆ†æçµæœã‚’ã¾ã¨ã‚ãŸã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ\"\"\"\n",
        "        report_str = \"# äººçš„ã‚·ãƒŠã‚¸ãƒ¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆ V2 (ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ç‰ˆ)\\n\\n\"\n",
        "\n",
        "        # 1. ç·åˆã‚·ãƒŠã‚¸ãƒ¼åˆ†æ\n",
        "        report_str += \"## 1. ç·åˆã‚·ãƒŠã‚¸ãƒ¼åˆ†æ\\n\"\n",
        "        synergy_df = pd.DataFrame(self.synergy_results['total_synergy'],\n",
        "                                  columns=self.names, index=self.names)\n",
        "        report_str += \"ç·åˆã‚·ãƒŠã‚¸ãƒ¼ãƒãƒˆãƒªã‚¯ã‚¹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:\\n\"\n",
        "        report_str += synergy_df.to_markdown() + \"\\n\\n\"\n",
        "\n",
        "        # 2. ã‚¹ã‚­ãƒ«è£œå®Œæ€§åˆ†æ\n",
        "        report_str += \"## 2. ã‚¹ã‚­ãƒ«è£œå®Œæ€§åˆ†æï¼ˆæ„å‘³ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰\\n\"\n",
        "        comp_df = pd.DataFrame(self.synergy_results['skill_complementarity'],\n",
        "                               columns=self.names, index=self.names)\n",
        "        report_str += \"ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å…¨ä½“ã®æ„å‘³çš„ãªè£œå®Œæ€§ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼ˆ1ã«è¿‘ã„ã»ã©è£œå®Œçš„ï¼‰:\\n\"\n",
        "        report_str += comp_df.to_markdown() + \"\\n\\n\"\n",
        "\n",
        "        # 3. ä¾¡å€¤è²¢çŒ®åº¦åˆ†æ\n",
        "        report_str += \"## 3. ä¾¡å€¤è²¢çŒ®åº¦åˆ†æï¼ˆã‚·ãƒ£ãƒ—ãƒ¬ãƒ¼å€¤ï¼‰\\n\"\n",
        "        report_str += \"ãƒãƒ¼ãƒ å…¨ä½“ã§å‰µå‡ºã•ã‚Œã‚‹ä¾¡å€¤ã«å¯¾ã™ã‚‹å„ãƒ¡ãƒ³ãƒãƒ¼ã®è²¢çŒ®åº¦ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:\\n\"\n",
        "        for name, val in zip(self.names, self.shapley_values):\n",
        "            report_str += f\"- {name}: {val:.3f}\\n\"\n",
        "        report_str += \"\\n\"\n",
        "\n",
        "        # 4. ç·æ‹¬\n",
        "        report_str += \"## 4. ç·æ‹¬\\n\"\n",
        "        report_str += \"æœ¬åˆ†æ(V2)ã¯ã€å„ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®æ„å‘³çš„ãªå†…å®¹ã‚’ç›´æ¥æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç¾å®Ÿã«å³ã—ãŸã‚·ãƒŠã‚¸ãƒ¼ã¨è²¢çŒ®åº¦ã‚’ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚\\n\"\n",
        "        report_str += \"ç‰¹ã«ã€ã‚¹ã‚­ãƒ«è£œå®Œæ€§ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´ã§ã¯ãªãã€æ–‡ç« å…¨ä½“ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’æ‰ãˆãŸçµæœã§ã™ã€‚\\n\"\n",
        "\n",
        "        return report_str\n",
        "\n",
        "# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¨è¡¨ç¤º\n",
        "report_generator = ReportGenerator(analysis_data, synergy_results, shapley_values)\n",
        "final_report = report_generator.generate_report()\n",
        "print(\"\\nğŸ“‹ V2: åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\\n\" + \"=\"*50)\n",
        "print(final_report)\n",
        "\n",
        "# ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "filename = f\"/content/drive/MyDrive/synergy_analysis_report_V2_{timestamp}.md\"\n",
        "try:\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(final_report)\n",
        "    print(f\"âœ… ãƒ¬ãƒãƒ¼ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n\\nğŸŠ å…¨ã¦ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼ ğŸŠ\")\n"
      ]
    }
  ]
}