{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe3KM4S1cSQYB3agJs/qVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyberust/HumanSynergyAnalysis/blob/main/HumanSynergySemanticAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKO4chrp6Qlc",
        "outputId": "d761d07d-d7fc-44c2-8339-e159d74acbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "#\n",
        "#  人的シナジー分析システム V2 - セマンティック分析版\n",
        "#\n",
        "#  V1からの改善点:\n",
        "#  - キーワードカウントベースの分析を廃止\n",
        "#  - sentence-transformers を用いた意味ベクトル（Embedding）による分析を導入\n",
        "#  - より精緻で信頼性の高いシナジー計算と価値貢献度分析を実現\n",
        "#\n",
        "# ======================================================================\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 1: 必要ライブラリのインストールと設定\n",
        "# ===============================================================\n",
        "\n",
        "# V2で新たに追加：意味ベクトル生成のためのライブラリ\n",
        "!pip install sentence-transformers --quiet\n",
        "\n",
        "# V1から継続して使用するライブラリ\n",
        "!pip install networkx matplotlib seaborn plotly kaleido --quiet\n",
        "!pip install scikit-learn pandas numpy scipy --quiet\n",
        "\n",
        "# Googleドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 基本ライブラリ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 数学・統計ライブラリ\n",
        "from scipy.integrate import odeint\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# NLP（自然言語処理）ライブラリ\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# その他\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"✅ V2: ライブラリのインストールと設定が完了しました\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 2: データ読み込み関数（V1から変更なし）\n",
        "# ===============================================================\n",
        "\n",
        "def load_profile_data():\n",
        "    \"\"\"Googleドライブからプロフィールデータを読み込む\"\"\"\n",
        "    base_path = \"/content/drive/MyDrive/\"\n",
        "    profiles = {}\n",
        "    names = [\"arale_cohen\", \"yanay_geva\", \"yasuyuki_sakane\"]\n",
        "    display_names = [\"Arale Cohen\", \"Yanay Geva\", \"Yasuyuki Sakane\"]\n",
        "\n",
        "    for name, display_name in zip(names, display_names):\n",
        "        try:\n",
        "            with open(f\"{base_path}{name}_profile.txt\", 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "            profiles[display_name] = content\n",
        "            print(f\"✅ {display_name}のプロフィールを読み込みました\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"⚠️ {name}_profile.txt が見つかりません。\")\n",
        "            profiles[display_name] = \"Profile data not available.\"\n",
        "    return profiles\n",
        "\n",
        "# データ読み込み実行\n",
        "profiles = load_profile_data()\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 3: 【V2の核心】セマンティック・プロフィール分析\n",
        "# ===============================================================\n",
        "\n",
        "class SemanticProfileAnalyzer:\n",
        "    def __init__(self):\n",
        "        # 事前学習済みの言語モデルをロード\n",
        "        # 'all-MiniLM-L6-v2' は高速かつ高品質な英語モデル\n",
        "        print(\"🤖 言語モデルをロード中...\")\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        print(\"✅ 言語モデルの準備が完了しました\")\n",
        "\n",
        "    def analyze_all_profiles(self, profiles_dict):\n",
        "        \"\"\"プロフィールテキストを意味ベクトルに変換し、他の特徴も抽出する\"\"\"\n",
        "        analysis_results = {}\n",
        "        profile_names = list(profiles_dict.keys())\n",
        "        profile_texts = list(profiles_dict.values())\n",
        "\n",
        "        # プロフィール全体を意味ベクトルに一括変換\n",
        "        print(\"🧠 全員のプロフィールを意味ベクトルに変換中...\")\n",
        "        embeddings = self.model.encode(profile_texts, show_progress_bar=True)\n",
        "        print(\"✅ ベクトル変換が完了しました\")\n",
        "\n",
        "        for i, name in enumerate(profile_names):\n",
        "            # 経験年数とネットワーク強度はV1のヒューリスティック手法を流用\n",
        "            # NOTE: これらの抽出方法も、将来的にはより高度化できる\n",
        "            experience = self._extract_experience_years(profile_texts[i])\n",
        "            network = self._extract_network_strength(profile_texts[i])\n",
        "\n",
        "            analysis_results[name] = {\n",
        "                'embedding': embeddings[i], # 意味ベクトル\n",
        "                'experience_years': experience,\n",
        "                'network_strength': network,\n",
        "                'raw_profile': profile_texts[i]\n",
        "            }\n",
        "        return analysis_results\n",
        "\n",
        "    def _extract_experience_years(self, text):\n",
        "        \"\"\"経験年数を抽出\"\"\"\n",
        "        matches = re.findall(r'(\\d+)\\+?\\s*years?', text.lower())\n",
        "        return max([int(match) for match in matches]) if matches else 10\n",
        "\n",
        "    def _extract_network_strength(self, text):\n",
        "        \"\"\"ネットワーク強度を推定\"\"\"\n",
        "        indicators = ['network', 'ecosystem', 'connections', 'board member', 'partner']\n",
        "        score = sum(text.lower().count(indicator) for indicator in indicators)\n",
        "        return min(score * 20, 100)\n",
        "\n",
        "# プロフィール分析実行\n",
        "analyzer = SemanticProfileAnalyzer()\n",
        "analysis_data = analyzer.analyze_all_profiles(profiles)\n",
        "\n",
        "print(\"✅ V2: セマンティック・プロフィール分析が完了しました\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 4: 【V2の核心】セマンティック・シナジー計算\n",
        "# ===============================================================\n",
        "\n",
        "class SemanticSynergyCalculator:\n",
        "    def __init__(self, analysis_data):\n",
        "        self.data = analysis_data\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def calculate_skill_complementarity(self):\n",
        "        \"\"\"意味ベクトル間のコサイン類似度を用いてスキル補完性を計算\"\"\"\n",
        "        # 全員の意味ベクトルをスタック\n",
        "        embeddings = np.array([self.data[name]['embedding'] for name in self.names])\n",
        "\n",
        "        # コサイン類似度を計算 (値が高いほどスキルセットが近い)\n",
        "        similarity_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "        # 補完性は (1 - 類似度) で定義\n",
        "        complementarity_matrix = 1 - similarity_matrix\n",
        "        return complementarity_matrix\n",
        "\n",
        "    def calculate_total_synergy_matrix(self):\n",
        "        \"\"\"総合シナジーマトリックスを計算\"\"\"\n",
        "        # V2: スキル補完性の計算方法が新しくなった\n",
        "        comp_matrix = self.calculate_skill_complementarity()\n",
        "\n",
        "        # V1から流用する計算ロジック\n",
        "        experiences = [self.data[name]['experience_years'] for name in self.names]\n",
        "        networks = [self.data[name]['network_strength'] for name in self.names]\n",
        "        exp_matrix = self._calculate_experience_synergy(experiences)\n",
        "        net_matrix = self._calculate_network_effects(networks)\n",
        "        div_matrix = self._calculate_cultural_diversity_bonus()\n",
        "\n",
        "        # 重み付き統合（調整可能）\n",
        "        weights = {\n",
        "            'complementarity': 0.4, # スキル補完性の重要度を上げる\n",
        "            'experience': 0.2,\n",
        "            'network': 0.2,\n",
        "            'diversity': 0.2\n",
        "        }\n",
        "\n",
        "        total_synergy = (\n",
        "            weights['complementarity'] * comp_matrix +\n",
        "            weights['experience'] * exp_matrix +\n",
        "            weights['network'] * net_matrix\n",
        "        ) * div_matrix # 多様性ボーナスは乗算で適用\n",
        "\n",
        "        # 自分自身とのシナジーは0にする\n",
        "        np.fill_diagonal(total_synergy, 0)\n",
        "\n",
        "        return {\n",
        "            'total_synergy': total_synergy,\n",
        "            'skill_complementarity': comp_matrix\n",
        "        }\n",
        "\n",
        "    # 以下はV1から流用するプライベートメソッド\n",
        "    def _calculate_experience_synergy(self, experiences):\n",
        "        synergy_matrix = np.zeros((3, 3))\n",
        "        for i, j in np.ndindex(synergy_matrix.shape):\n",
        "            if i != j:\n",
        "                exp_diff = abs(experiences[i] - experiences[j])\n",
        "                synergy_matrix[i, j] = np.exp(-0.1 * exp_diff) # 差が小さいほど高い\n",
        "        return synergy_matrix\n",
        "\n",
        "    def _calculate_network_effects(self, networks):\n",
        "        network_matrix = np.zeros((3, 3))\n",
        "        for i, j in np.ndindex(network_matrix.shape):\n",
        "            if i != j:\n",
        "                network_matrix[i, j] = (networks[i] * networks[j]) / 10000.0\n",
        "        return network_matrix\n",
        "\n",
        "    def _calculate_cultural_diversity_bonus(self):\n",
        "        backgrounds = {'Arale Cohen': 'Western', 'Yanay Geva': 'Western', 'Yasuyuki Sakane': 'Eastern'}\n",
        "        diversity_matrix = np.ones((3, 3))\n",
        "        for i, name1 in enumerate(self.names):\n",
        "            for j, name2 in enumerate(self.names):\n",
        "                if backgrounds[name1] != backgrounds[name2]:\n",
        "                    diversity_matrix[i, j] = 1.2 # 異なる文化背景に20%のボーナス\n",
        "        return diversity_matrix\n",
        "\n",
        "# シナジー計算実行\n",
        "synergy_calc = SemanticSynergyCalculator(analysis_data)\n",
        "synergy_results = synergy_calc.calculate_total_synergy_matrix()\n",
        "\n",
        "print(\"✅ V2: セマンティック・シナジー計算が完了しました\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 5: 動的システムモデリング（安定版を標準搭載）\n",
        "# ===============================================================\n",
        "\n",
        "# 以前の対話で安定化した最終版のモデルをデフォルトとして使用\n",
        "class DynamicSystemModel:\n",
        "    def __init__(self, synergy_results, analysis_data):\n",
        "        self.synergy_matrix = synergy_results['total_synergy']\n",
        "        self.data = analysis_data\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def define_system_parameters(self):\n",
        "        \"\"\"システムパラメータを定義（安定性を最優先したロジスティック成長モデル）\"\"\"\n",
        "        alpha = np.array([0.4, 0.35, 0.45]) # 個人の基礎成長率\n",
        "        beta = self.synergy_matrix * 0.1 # シナジー効果\n",
        "        K = np.array([12.0, 12.0, 12.0]) # パフォーマンス上限\n",
        "        return alpha, beta, K\n",
        "\n",
        "    def system_dynamics(self, state, t, alpha, beta, K):\n",
        "        \"\"\"動的システム方程式（結合ロジスティック成長モデル）\"\"\"\n",
        "        x1, x2, x3 = state\n",
        "        dx1dt = (alpha[0] * x1 + beta[0,1] * x2 + beta[0,2] * x3) * (1 - x1 / K[0])\n",
        "        dx2dt = (alpha[1] * x2 + beta[1,0] * x1 + beta[1,2] * x3) * (1 - x2 / K[1])\n",
        "        dx3dt = (alpha[2] * x3 + beta[2,0] * x1 + beta[2,1] * x2) * (1 - x3 / K[2])\n",
        "        return [dx1dt, dx2dt, dx3dt]\n",
        "\n",
        "    def simulate_growth(self, initial_state=None, time_horizon=24):\n",
        "        \"\"\"成長シミュレーション実行\"\"\"\n",
        "        if initial_state is None:\n",
        "            initial_state = [1.0, 1.0, 1.0] # ベースラインを1.0に設定\n",
        "        alpha, beta, K = self.define_system_parameters()\n",
        "        t = np.linspace(0, time_horizon, time_horizon * 4)\n",
        "        solution = odeint(self.system_dynamics, initial_state, t, args=(alpha, beta, K))\n",
        "        return t, solution, (alpha, beta, K)\n",
        "\n",
        "# 動的システムシミュレーション実行\n",
        "dynamic_model = DynamicSystemModel(synergy_results, analysis_data)\n",
        "time_axis, growth_solution, _ = dynamic_model.simulate_growth()\n",
        "\n",
        "print(\"✅ V2: 動的システムモデリングが完了しました\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 6: ゲーム理論分析（より意味のある入力で実行）\n",
        "# ===============================================================\n",
        "# V2の精緻化されたシナジー値を入力として使用するため、\n",
        "# ゲーム理論分析の結果も、より現実的なものになることが期待される\n",
        "\n",
        "class GameTheoryAnalysis:\n",
        "    def __init__(self, synergy_results, analysis_data):\n",
        "        self.synergy_matrix = synergy_results['total_synergy']\n",
        "        self.data = analysis_data\n",
        "        self.names = list(analysis_data.keys())\n",
        "        self.n_players = len(self.names)\n",
        "\n",
        "    def _get_coalition_value(self, coalition_indices):\n",
        "        \"\"\"連合の価値を計算する関数\"\"\"\n",
        "        if not coalition_indices:\n",
        "            return 0\n",
        "\n",
        "        # 連合内の個人の基礎価値の合計\n",
        "        base_value = sum((self.data[self.names[i]]['experience_years'] +\n",
        "                          self.data[self.names[i]]['network_strength'] / 10.0)\n",
        "                         for i in coalition_indices)\n",
        "\n",
        "        # 連合内のシナジーの合計\n",
        "        synergy_value = 0\n",
        "        if len(coalition_indices) > 1:\n",
        "            for i in coalition_indices:\n",
        "                for j in coalition_indices:\n",
        "                    synergy_value += self.synergy_matrix[i, j]\n",
        "\n",
        "        # 基礎価値とシナジー価値を統合\n",
        "        return base_value + synergy_value * 5 # シナジーの価値を強調\n",
        "\n",
        "    def calculate_shapley_values(self):\n",
        "        \"\"\"シャプレー値を計算\"\"\"\n",
        "        from math import factorial\n",
        "        from itertools import combinations\n",
        "\n",
        "        shapley_values = np.zeros(self.n_players)\n",
        "        all_players_set = set(range(self.n_players))\n",
        "\n",
        "        for i in range(self.n_players):\n",
        "            for coalition_size in range(self.n_players):\n",
        "                num_combinations = 0\n",
        "                total_marginal_contribution = 0\n",
        "\n",
        "                other_players = list(all_players_set - {i})\n",
        "                for coalition in combinations(other_players, coalition_size):\n",
        "                    coalition_with_i = list(coalition) + [i]\n",
        "                    coalition_without_i = list(coalition)\n",
        "\n",
        "                    marginal_contribution = self._get_coalition_value(coalition_with_i) - self._get_coalition_value(coalition_without_i)\n",
        "                    shapley_values[i] += marginal_contribution\n",
        "\n",
        "        # 正規化\n",
        "        total_value_all_players = self._get_coalition_value(list(all_players_set))\n",
        "        current_total_shapley = np.sum(shapley_values)\n",
        "        if current_total_shapley > 0:\n",
        "            shapley_values = (shapley_values / current_total_shapley) * total_value_all_players\n",
        "\n",
        "        return shapley_values\n",
        "\n",
        "# ゲーム理論分析実行\n",
        "game_analysis = GameTheoryAnalysis(synergy_results, analysis_data)\n",
        "shapley_values = game_analysis.calculate_shapley_values()\n",
        "\n",
        "print(\"✅ V2: ゲーム理論分析が完了しました\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 7: 予測モデリング（安定した入力で実行）\n",
        "# ===============================================================\n",
        "\n",
        "class PredictionModel:\n",
        "    def __init__(self, growth_solution, time_axis, synergy_results):\n",
        "        self.growth_data = growth_solution\n",
        "        self.time_axis = time_axis\n",
        "        self.synergy_matrix = synergy_results['total_synergy']\n",
        "\n",
        "    def forecast_business_metrics(self):\n",
        "        \"\"\"ビジネス指標予測\"\"\"\n",
        "        performance_data = []\n",
        "        for t in range(len(self.time_axis)):\n",
        "            individual_performance = self.growth_data[t]\n",
        "            # team_synergy の計算式をより安定なものに\n",
        "            team_synergy = np.sum(self.synergy_matrix * np.outer(individual_performance, individual_performance)) / 2\n",
        "\n",
        "            # 各指標の計算\n",
        "            revenue_growth = np.sum(individual_performance) * 10 + team_synergy * 5\n",
        "            innovation_index = team_synergy * 10\n",
        "            market_share = min(np.sum(individual_performance) + team_synergy, 40)\n",
        "            customer_satisfaction = min(75 + team_synergy, 98)\n",
        "\n",
        "            performance_data.append({\n",
        "                'time_months': self.time_axis[t],\n",
        "                'revenue_growth_rate': revenue_growth,\n",
        "                'innovation_index': innovation_index,\n",
        "                'market_share_percent': market_share,\n",
        "                'customer_satisfaction': customer_satisfaction\n",
        "            })\n",
        "        return pd.DataFrame(performance_data)\n",
        "\n",
        "# 予測モデリング実行\n",
        "prediction_model = PredictionModel(growth_solution, time_axis, synergy_results)\n",
        "business_forecast = prediction_model.forecast_business_metrics()\n",
        "\n",
        "print(\"✅ V2: 予測モデリングが完了しました\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 8: 可視化エンジン（V1からコード流用、描画内容が変化）\n",
        "# ===============================================================\n",
        "\n",
        "# V1のVisualizationEngineは、入力データが変わることで\n",
        "# V2の分析結果を可視化する役割を担う\n",
        "class VisualizationEngine:\n",
        "    def __init__(self, analysis_data, synergy_results, growth_solution,\n",
        "                 time_axis, business_forecast, shapley_values):\n",
        "        self.analysis_data = analysis_data\n",
        "        self.synergy_results = synergy_results\n",
        "        self.growth_solution = growth_solution\n",
        "        self.time_axis = time_axis\n",
        "        self.business_forecast = business_forecast\n",
        "        self.shapley_values = shapley_values\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def create_synergy_heatmap(self):\n",
        "        \"\"\"総合シナジーヒートマップ\"\"\"\n",
        "        synergy_matrix = self.synergy_results['total_synergy']\n",
        "        fig = px.imshow(synergy_matrix,\n",
        "                        labels=dict(x=\"メンバー\", y=\"メンバー\", color=\"シナジー強度\"),\n",
        "                        x=self.names, y=self.names,\n",
        "                        text_auto='.3f',\n",
        "                        color_continuous_scale='Blues')\n",
        "        fig.update_layout(title_text='V2: 総合シナジーマトリックス（セマンティック版）')\n",
        "        return fig\n",
        "\n",
        "    def create_growth_trajectory(self):\n",
        "        \"\"\"動的成長軌道\"\"\"\n",
        "        df = pd.DataFrame(self.growth_solution, columns=self.names)\n",
        "        df['Time'] = self.time_axis\n",
        "        fig = px.line(df, x='Time', y=self.names,\n",
        "                      labels={'value': 'パフォーマンス指数', 'Time': '時間（月）'},\n",
        "                      title='V2: 動的成長軌道シミュレーション（安定版）')\n",
        "        return fig\n",
        "\n",
        "    def create_business_metrics_dashboard(self):\n",
        "        \"\"\"ビジネス指標ダッシュボード\"\"\"\n",
        "        df = self.business_forecast\n",
        "        fig = make_subplots(rows=2, cols=2, subplot_titles=('売上成長率', 'イノベーション指数', 'マーケットシェア', '顧客満足度'))\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['revenue_growth_rate'], name='売上成長率'), row=1, col=1)\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['innovation_index'], name='イノベーション指数'), row=1, col=2)\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['market_share_percent'], name='マーケットシェア'), row=2, col=1)\n",
        "        fig.add_trace(go.Scatter(x=df['time_months'], y=df['customer_satisfaction'], name='顧客満足度'), row=2, col=2)\n",
        "        fig.update_layout(title_text='V2: ビジネス指標予測ダッシュボード', showlegend=False)\n",
        "        return fig\n",
        "\n",
        "    def create_shapley_value_chart(self):\n",
        "        \"\"\"シャプレー値による価値貢献度\"\"\"\n",
        "        fig = px.bar(x=self.names, y=self.shapley_values,\n",
        "                     labels={'x': 'メンバー', 'y': '価値貢献度（シャプレー値）'},\n",
        "                     text=np.round(self.shapley_values, 2),\n",
        "                     title='V2: シャプレー値による価値貢献度分析')\n",
        "        return fig\n",
        "\n",
        "    def create_network_graph(self):\n",
        "        \"\"\"V1のバグを修正したネットワークグラフ\"\"\"\n",
        "        G = nx.Graph()\n",
        "        for i, name in enumerate(self.names):\n",
        "            G.add_node(name, size=self.analysis_data[name]['network_strength'])\n",
        "\n",
        "        synergy_matrix = self.synergy_results['total_synergy']\n",
        "        for i, j in np.ndindex(synergy_matrix.shape):\n",
        "            if i < j:\n",
        "                G.add_edge(self.names[i], self.names[j], weight=synergy_matrix[i, j])\n",
        "\n",
        "        pos = nx.spring_layout(G, k=1.5, iterations=50)\n",
        "\n",
        "        edge_traces = []\n",
        "        for edge in G.edges(data=True):\n",
        "            x0, y0 = pos[edge[0]]\n",
        "            x1, y1 = pos[edge[1]]\n",
        "            w = edge[2]['weight'] * 15\n",
        "            edge_traces.append(go.Scatter(x=[x0, x1, None], y=[y0, y1, None], mode='lines',\n",
        "                                        line=dict(width=w, color='rgba(150,150,150,0.5)'),\n",
        "                                        hoverinfo='text', text=f\"Synergy: {w/15:.3f}\"))\n",
        "\n",
        "        node_trace = go.Scatter(x=[pos[n][0] for n in G.nodes()],\n",
        "                                y=[pos[n][1] for n in G.nodes()],\n",
        "                                mode='markers+text',\n",
        "                                text=self.names, textposition=\"top center\",\n",
        "                                marker=dict(size=[d['size']/5 for n, d in G.nodes(data=True)],\n",
        "                                            color=['#FF6B6B', '#4ECDC4', '#45B7D1']),\n",
        "                                hoverinfo='none')\n",
        "\n",
        "        fig = go.Figure(data=edge_traces + [node_trace],\n",
        "                        layout=go.Layout(title='V2: チーム相互作用ネットワーク', showlegend=False,\n",
        "                                         xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                                         yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
        "        return fig\n",
        "\n",
        "    def generate_all_visualizations(self):\n",
        "        \"\"\"全ての可視化を生成・表示\"\"\"\n",
        "        print(\"\\n📊 V2: 可視化を生成中...\")\n",
        "\n",
        "        # V2で意味を持つようになったグラフを中心に可視化\n",
        "        self.create_synergy_heatmap().show()\n",
        "        self.create_growth_trajectory().show()\n",
        "        self.create_business_metrics_dashboard().show()\n",
        "        self.create_shapley_value_chart().show()\n",
        "        self.create_network_graph().show()\n",
        "\n",
        "        print(\"✅ V2: 全ての可視化が完了しました\")\n",
        "\n",
        "# 可視化エンジン実行\n",
        "viz_engine = VisualizationEngine(analysis_data, synergy_results, growth_solution,\n",
        "                                 time_axis, business_forecast, shapley_values)\n",
        "viz_engine.generate_all_visualizations()\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 9: 包括的レポート生成\n",
        "# ===============================================================\n",
        "# V2の分析結果に基づいたレポートを生成\n",
        "\n",
        "class ReportGenerator:\n",
        "    def __init__(self, analysis_data, synergy_results, shapley_values):\n",
        "        self.analysis_data = analysis_data\n",
        "        self.synergy_results = synergy_results\n",
        "        self.shapley_values = shapley_values\n",
        "        self.names = list(analysis_data.keys())\n",
        "\n",
        "    def generate_report(self):\n",
        "        \"\"\"分析結果をまとめたサマリーレポートを生成\"\"\"\n",
        "        report_str = \"# 人的シナジー分析レポート V2 (セマンティック版)\\n\\n\"\n",
        "\n",
        "        # 1. 総合シナジー分析\n",
        "        report_str += \"## 1. 総合シナジー分析\\n\"\n",
        "        synergy_df = pd.DataFrame(self.synergy_results['total_synergy'],\n",
        "                                  columns=self.names, index=self.names)\n",
        "        report_str += \"総合シナジーマトリクスは以下の通りです:\\n\"\n",
        "        report_str += synergy_df.to_markdown() + \"\\n\\n\"\n",
        "\n",
        "        # 2. スキル補完性分析\n",
        "        report_str += \"## 2. スキル補完性分析（意味ベクトルベース）\\n\"\n",
        "        comp_df = pd.DataFrame(self.synergy_results['skill_complementarity'],\n",
        "                               columns=self.names, index=self.names)\n",
        "        report_str += \"プロフィール全体の意味的な補完性は以下の通りです（1に近いほど補完的）:\\n\"\n",
        "        report_str += comp_df.to_markdown() + \"\\n\\n\"\n",
        "\n",
        "        # 3. 価値貢献度分析\n",
        "        report_str += \"## 3. 価値貢献度分析（シャプレー値）\\n\"\n",
        "        report_str += \"チーム全体で創出される価値に対する各メンバーの貢献度は以下の通りです:\\n\"\n",
        "        for name, val in zip(self.names, self.shapley_values):\n",
        "            report_str += f\"- {name}: {val:.3f}\\n\"\n",
        "        report_str += \"\\n\"\n",
        "\n",
        "        # 4. 総括\n",
        "        report_str += \"## 4. 総括\\n\"\n",
        "        report_str += \"本分析(V2)は、各メンバーのプロフィールの意味的な内容を直接比較することで、より現実に即したシナジーと貢献度を算出しています。\\n\"\n",
        "        report_str += \"特に、スキル補完性はキーワードの一致ではなく、文章全体のニュアンスを捉えた結果です。\\n\"\n",
        "\n",
        "        return report_str\n",
        "\n",
        "# レポート生成と表示\n",
        "report_generator = ReportGenerator(analysis_data, synergy_results, shapley_values)\n",
        "final_report = report_generator.generate_report()\n",
        "print(\"\\n📋 V2: 分析レポート\\n\" + \"=\"*50)\n",
        "print(final_report)\n",
        "\n",
        "# レポートをファイルに保存\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "filename = f\"/content/drive/MyDrive/synergy_analysis_report_V2_{timestamp}.md\"\n",
        "try:\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(final_report)\n",
        "    print(f\"✅ レポートが保存されました: {filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ レポート保存中にエラーが発生しました: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n🎊 全ての分析が完了しました！ 🎊\")\n"
      ]
    }
  ]
}